{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Distributions, Dates, Gadfly, GLM, Statistics, Random, Plots, MultivariateStats, StatsBase, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation des fichiers CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On devrait surement faire le split 80/20 juste avant la création du modèle et appeler toutes nos fonction d'encoding sur la variables full_train et non 2 fois sur train et valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En raison du score basé sur le RMSLE, nous avons conclu que l'entrainement du modèle sur les bateau ayant des prix inférieur à 100k$ était d'avantage performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"Data/train.csv\", DataFrame)\n",
    "test = CSV.read(\"Data/test.csv\", DataFrame)\n",
    "\n",
    "\n",
    "Random.seed!(3302)\n",
    "\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compréhension de la métrique RMSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperçu de RMSLE\n",
    "\n",
    "La racine carrée de l'erreur quadratique moyenne logarithmique (RMSLE) est une mesure de la précision des valeurs prédites. Cependant elle se distincue de la somme des erreurs au carré (SSE) par le fait qu'elle pénalise les erreurs de prédiction des valeurs les plus élevées plus que les erreurs de prédiction des valeurs les plus faibles. Par conséquent, nous nos devrons s'assurer que, dans le cas ou notre modèle voit des valeurs supérieurs a sont ensemble d'entrainement, nous essayerons que notre preédiction soit inférieu et non supérieur a la valeur réelle afin de minimiser la pénalité. \n",
    "\n",
    "En effet cette approche est différente de celle aborde tout au long de la regression linéaire et bayesienne sachanque que nous voulions habutuellement que notre modèle pénalise équitablement pour les valeurs supérieurs et inférieurs aux valeurs prédictes.\n",
    "\n",
    "C'est donc pour cette raison que vous aller régulièrement nous voir couper des valeurs réelles de notre ensemble d'entrainement qui semble être majoritairement supérieur a la moyenne observé. De cette façon, nous minimiserons les probabilités que notre modèle de prediction prédisent des valeurs supérieurs a la réalité sachant qu'il n'a jamais vu de telles valeurs lors de l'entrainement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rmsle(predictions::Vector{Int64}, actual::Vector{Int64})\n",
    "    if length(predictions) != length(actual)\n",
    "        throw(ArgumentError(\"Les vecteurs de prédictions et de valeurs réelles doivent avoir la même longueur\"))\n",
    "    end\n",
    "    \n",
    "    n = length(predictions)\n",
    "    sum_squared_log_errors = 0\n",
    "    \n",
    "    for i in 1:n\n",
    "        sum_squared_log_errors += (log(predictions[i] + 1) - log(actual[i] + 1))^2\n",
    "    end\n",
    "    \n",
    "    rmsle_score = sqrt(sum_squared_log_errors / n)\n",
    "    return rmsle_score\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploration des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Matrice de correlation entre les variables\n",
    "\n",
    "Nous avons décidé de faire une matrice de corrélation entre toutes variables du set de données afin d'avoir une idée générale de la puissance de corrélation. Cependant, il est important de noter que cette matrice ne définit que les relations 1:1 entres les variables, par conséquent nous devrons faire des analyses plus poussées afin de comprendre les lien entres plusieurs variables combinées. \n",
    "\n",
    "Toutefois, il est possible de remarquer que les variables les plus corrélées avec la variable cible sont : Longueur, Poids et Puissance_Moteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(full_train)\n",
    "data = dropmissing(data)\n",
    "\n",
    "\n",
    "cols = [:Année, :Largeur, :Longueur, :Poids, :Nombre_Moteurs, :Puissance_Moteur, :Mois_Vente, :Année_Vente, :Prix]  # define subset\n",
    "M = cor(Matrix(data[!,cols]))       # correlation matrix\n",
    "\n",
    "# PLOT\n",
    "(n,m) = size(M)\n",
    "heatmap(M, fc=cgrad([:white,:dodgerblue4]), xticks=(1:m,cols), xrot=90, yticks=(1:m,cols), yflip=true)\n",
    "annotate!([(j, i, text(round(M[i,j],digits=3), 8,\"Computer Modern\",:black)) for i in 1:n for j in 1:m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Présentation des données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de remarquer que les colonnes Largeur, Poids, Carburant, Puissance_moteur ainsi que Type_Moteur possèdent des données manquantes. Nous allons donc devoir les traiter si nous voulons les utiliser pour l'entrainement de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = mapcols(x -> count(ismissing, x), full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(12cm, 10cm)\n",
    "Gadfly.plot(train, x=:Type, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon le type d'embarcation\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les bateaux alimentés peuvent atteindre des prix très élevés, et que les bateux à voile peuvent aussi parfois être vendus très chers (plus de 1M de dollars) tandis que les bateux non alimentés n'atteignent jamais des prix exorbitants. Cela est sensé si l'on se dit que les bateux non alimentés s'agissent probablement de plus petites petites embarcations comme des kayaks, entre autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations motorisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(30cm, 10cm)\n",
    "emb_motorises = filter(row -> row.Type == \"power\", train)\n",
    "Gadfly.plot(emb_motorises, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation motorisée\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir il existe beaucoup de différentes classes pour chaque type d'embarcation. Pour plusieurs d'entre-elles, les prix semblent rester dans des ordres similaires. Cependant, comme on peut le voir par le précédent graphique, certaines classes peuvent atteindre des prix plus élevés et certaines semblent même en moyenne se vendre considérablement plus cher que d'autres, notamment les classe \"power-mega\" et \"power-passenger\". D'autres ont des prix plus bas en moyenne comme \"power-util\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_motorises, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations à voile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 10cm)\n",
    "emb_voile = filter(row -> row.Type == \"sail\", train)\n",
    "Gadfly.plot(emb_voile, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation à voile\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est des bateaux à voile, les embarcations de la classe \"sail-catamaran\" se démarquent selon leur prix de vente qui semble être considérablement plus élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_voile, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations non motorisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 10cm)\n",
    "emb_non_motorises = filter(row -> row.Type == \"unpowered\", train)\n",
    "Gadfly.plot(emb_non_motorises, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation non-motorisée\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, il semble que les embarcations \"unpowered-tender\" semblent être celles qui se vendent plus cher parmi les bateaux non motorisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_non_motorises, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bref la classe d'une embarcation peut certainement donner de la bonne information pour estimer son prix. Cependant, certaines classes sont plus communes dans les données que d'autres et offrent donc de meilleures estimations, tandis que d'autres sont plus rares et risquent d'être moins pertinents. De plus, il est très possible que de nouvelles données ajoutent de nouvelles classes non présentes dans celles d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fabricant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants = combine(groupby(train, :Fabricant), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))\n",
    "dropmissing!(fabricants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regroupant les données selon le fabricant, on remarque qu'il y a plus de 600 de ces derniers. Pour mieux se donner une idée de l'impact que le fabricant a sur le prix de vente final on peut donc décider de jeter un coup d'oeil aux fabricants dont le prix de vente est en moyenne le plus élevé et ceux dont le prix de vente est en moyenne le plus bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants[partialsortperm(fabricants.Prix_Moyen, 1:10, rev=true), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants[partialsortperm(fabricants.Prix_Moyen, 1:10), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, pour certains fabricants, le prix de vente moyen de leur embarcations est très bas (entre 500 et 2000 dollars) tandis que pour d'autres, le prix est assez exorbitant (entre 1 et 2.75M de dollars). Le fabricant d'une embarcation peut donc être une information très utile pour déterminer son prix. Cependant, il y a énormément de divers fabricants et il n'y a aucune assurance que de nouvelles données n'introduisent pas de nouveux fabricants dont la moyenne de prix de vente est inconnue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_modèle_train = unique(train[:, :Modèle]); \n",
    "println(\"Number of unique categories: \", length(unique_modèle_train))\n",
    "unique_modèle_valid = unique(valid[:, :Modèle]);\n",
    "missing_modèles = setdiff(unique_modèle_valid, unique_modèle_train);\n",
    "println(\"Initially missing \" * string(length(missing_modèles)) * \" modèles in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe énormément de modèles de bateau différents (5668) et ceux-ci se répètent très peu, nous avons ainsi des doutes sur la pertinence de cette colonne de données. De plus, cette colonne est présentement inutilisation dans un modèle. Il faudra encoder un algorithme one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration = dropmissing(train, :Modèle)\n",
    "unique_categories = unique(skipmissing(exploration[:, :Modèle]))\n",
    "occurences = [sum(skipmissing(exploration[:, :Modèle]) .== category) for category in unique_categories]\n",
    "occurences = DataFrame(category = unique_categories, occurences = occurences)\n",
    "occurences = occurences[occurences.occurences .> 1, :]\n",
    "\n",
    "function calculate_statistics(category)\n",
    "    subset_data = exploration[exploration[:, :Modèle] .== category, :Prix]\n",
    "    min_prix = minimum(subset_data)\n",
    "    max_prix = maximum(subset_data)\n",
    "    mean_prix = mean(skipmissing(subset_data))\n",
    "    return (min_prix = min_prix, max_prix = max_prix, mean_prix = mean_prix)\n",
    "end\n",
    "\n",
    "prix_statistics = DataFrame([calculate_statistics(category) for category in occurences[:, :category]])\n",
    "occurences = hcat(occurences, prix_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tableau nous démontre que le modèle est un excellant prédicteur de prix. Le seul désavantage à celui-ci est qu'il en existe beaucoup. De ce fait, plusieurs modèles se retrouvent dans l'ensemble de test, mais ne sont jamais vus dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacement des variables \"Missing\" par une autre catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceValue = \"Autre\"\n",
    "train[!, :Modèle] = coalesce.(train[!, :Modèle], replaceValue);\n",
    "valid[!, :Modèle] = coalesce.(valid[!, :Modèle], replaceValue);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant sert à associer à chaque modèle connu à un intervalle de prix. Pour se faire nous utilisons la moyenne qui est plus performante que la médiane en raison de la quantité imposante de modèles observés uniquement 2 fois dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_ranges = [\n",
    "    (\"Under5k\", 0, 5000),\n",
    "    (\"5kto10k\", 5001, 10000),\n",
    "    (\"10kto15k\", 10001, 15000),\n",
    "    (\"15kto20k\", 15001, 20000),\n",
    "    (\"20kto25k\", 20001, 25000),\n",
    "    (\"25kto30k\", 25001, 30000),\n",
    "    (\"30kto35k\", 30001, 35000),\n",
    "    (\"35kto40k\", 35001, 40000),\n",
    "    (\"40kto45k\", 40001, 45000),\n",
    "    (\"45kto50k\", 45001, 50000),\n",
    "    (\"50kto55k\", 50001, 55000),\n",
    "    (\"55kto60k\", 55001, 60000),\n",
    "    (\"60kto65k\", 60001, 65000),\n",
    "    (\"65kto70k\", 65001, 70000),\n",
    "    (\"70kto75k\", 70001, 75000),\n",
    "    (\"75kto80k\", 75001, 80000),\n",
    "    (\"80kto85k\", 80001, 85000),\n",
    "    (\"85kto90k\", 85001, 90000),\n",
    "    (\"90kto95k\", 90001, 95000),\n",
    "    (\"95kto100k\", 95001, 100000)\n",
    "]\n",
    "\n",
    "# Function to assign category based on price\n",
    "function assign_category(price)\n",
    "    for (category, min_price, max_price) in price_ranges\n",
    "        if price >= min_price && price <= max_price\n",
    "            return category\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivant sert à encoder selon one-hot les tranches de prix prédéfinies plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_category_Model!(df::DataFrame, category_mapping::DataFrame, model_col::Symbol)\n",
    "    categories = unique(category_mapping.Category)\n",
    "    for category in categories\n",
    "        df[!, Symbol(\"is\", category)] = zeros(Int, nrow(df))\n",
    "    end\n",
    "\n",
    "    missing_modèle_counter = 0\n",
    "    for i in 1:nrow(df)\n",
    "        model = df[i, model_col]\n",
    "        matching_rows = filter(row -> row.Model == model, category_mapping)\n",
    "        \n",
    "        if isempty(matching_rows)\n",
    "            category = \"20kto25k\" #0.6455753480203078 #maximise le score rmsle\n",
    "            missing_modèle_counter += 1\n",
    "        else\n",
    "            category = matching_rows[1, :Category]\n",
    "        end\n",
    "    \n",
    "        df[i, Symbol(\"is\", category)] = 1\n",
    "    end\n",
    "    println(\"Missing modèles count: \", missing_modèle_counter)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1 : Tester avec le modèle. Les tests suivant (1-3) avec le rmsle sont pertinant sont d'évaluer la meilleure utilisation de la variable modèle. Les vrais test pour la prédiction du prix se trouve uniquement à vers la fin du rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by boat model and calculating mean price\n",
    "merged_df = combine(groupby(train, :Modèle), :Prix => mean => :Mean_Price)\n",
    "# Apply function to assign category to each model\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle, Category = map(assign_category, merged_df.Mean_Price))\n",
    "# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Modèle)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle)\n",
    "\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'améliorer le modèle en réduisant le nombre de modèles jamais vus. Pour ce faire, tentons de trouver des noms de modèles très similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_modèles = unique(train[!, :Modèle])\n",
    "regex_pattern = r\"\\D+\"\n",
    "# Function to extract the non-numeric part of the 'Modèle' string\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "# Apply the function to create a new column 'Modèle_New' in the train DataFrame\n",
    "train[!, :Modèle_New] = coalesce.(extract_model_name.(train[!, :Modèle]), \"Other\")\n",
    "valid[!, :Modèle_New] = coalesce.(extract_model_name.(valid[!, :Modèle]), \"Other\")\n",
    "\n",
    "# Extract unique values of 'Modèle_New' from both datasets\n",
    "unique_data_modèles = unique(train[!, :Modèle_New])\n",
    "println(\"Number of unique modèle in train: \", length(unique_data_modèles))\n",
    "unique_valid_modèles = unique(valid[!, :Modèle_New])\n",
    "println(\"Number of unique modèle in valid: \", length(unique_valid_modèles))\n",
    "diff_modèles = setdiff(unique_valid_modèles, unique_data_modèles)\n",
    "println(\"Now missing \" * string(length(diff_modèles)) * \" modèles in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cette façon, c'est à dire en oubliant les majuscules et les chiffres, nous passons de 775 à 245 modèles présents dans l'ensemble de validation, mais manquants dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #2 : Testons avec le modèle modifié (suppressions caractères spéciaux et chiffres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Modèle_New), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle_New, Category = map(assign_category, merged_df.Mean_Price))# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Modèle_New)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle_New)\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #3 : Test avec la nouvelle colonne FabModele et en réduisant avec un regex les strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée suivante provient d'une remarque au niveau du déboguage, que plusieurs modèle étaient jumelé alors que ceux-ci ne possedait pas le même fabricant cause de mauvaises probabilités avec un score rmsle plus élevés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi ce test Réusini les variables fabricant et modèle, puis utilise un regex pour enlever les chiffres et les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'Fab_Model\" in the train and valid DataFrame\n",
    "train[!, :Fab_Model] = train[!, :Fabricant] .* \"_\" .* train[!, :Modèle]\n",
    "valid[!, :Fab_Model] = valid[!, :Fabricant] .* \"_\" .* valid[!, :Modèle];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_modèles = unique(train[!, :Fab_Model])\n",
    "regex_pattern = r\"\\D+\"\n",
    "# Function to extract the non-numeric part of the 'Modèle' string\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "# Apply the function to create a new column 'Modèle_New' in the train DataFrame\n",
    "train[!, :Fab_Model] = coalesce.(extract_model_name.(train[!, :Fab_Model]), \"Other\")\n",
    "valid[!, :Fab_Model] = coalesce.(extract_model_name.(valid[!, :Fab_Model]), \"Other\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Fab_Model), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Fab_Model, Category = map(assign_category, merged_df.Mean_Price))# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Fab_Model)\n",
    "encode_category_Model!(valid, model_mapping, :Fab_Model)\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Année et années de vente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_age(df::DataFrame)\n",
    "    df[!, :Age] = df[!, :Année_Vente] .- df[!, :Année]\n",
    "    logAge = ifelse.(df[!, :Age] .<= 0, 1, df[!, :Age])\n",
    "    #logAge\n",
    "    df[!, :LogAge] = (log.(logAge))\n",
    "end\n",
    "\n",
    "encode_age(full_train);\n",
    "\n",
    "full_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots.plot(full_train.Age, x=:Age, y=:Prix, Geom.point)\n",
    "\n",
    "set_default_plot_size(40cm, 20cm)\n",
    "\n",
    "plot1 = Gadfly.plot(full_train, x=:Age, y=:Prix, color=:Type, Geom.point)\n",
    "plot2 = Gadfly.plot(full_train, x=:LogAge, y=:Prix, color=:Type, Geom.point)\n",
    "\n",
    "hstack(plot1, plot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = filter(row -> !ismissing(row.Condition), train)\n",
    "set_default_plot_size(15cm, 10cm)\n",
    "Gadfly.plot(condition, x=:Condition, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon sa condition\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant une échelle de log à base 10 pour l'axe du prix pour une meilleure visibilité, on peut voir que la condition semble avoir en général peu d'importance pour prédire le prix de vente d'une embarcation. Comme on peut le voir par le précédent graphique, que l'embarcation soit neuve ou usagée, les prix de vente sont relativement similaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longueur = filter(row -> !ismissing(row.Longueur), train)\n",
    "Gadfly.plot(longueur, x=:Longueur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir possiblement une certaine corrélation entre la longueur d'une embarcation et son prix, ce qui n'est pas tout à fait surprenant. En effet, on peut faire l'hypothèse qu'en général plus une embarcation est longue, plus elle est grande et donc probablement plus coûteuse. Cependant des embarcation très longues et peu larges (très fines) ne sont pas nécéssairement alors si massives et pas autant coûteuses. Ce n'est donc pas une corrélation parfaite. Tout de même, certaines valeurs semblent être assez aberrantes, notamment les embarcations notées à des longueurs de plus de 150 pieds et dont le prix est relativement bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Longueur < 150, longueur)\n",
    "Gadfly.plot(longueur, x=:Longueur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeur = filter(row -> !ismissing(row.Largeur), train)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En prenant les données brutes, on remarque qu'il semble y avoir des données aberrantes d'embarcations aux largeurs énormes s'étant vendues à un prix relativement bas. Il vaut donc la peine de retirer ces embarcations pour mieux observer l'effet de la largeur sur le prix de vente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Largeur < 500, largeur)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En excluant des valeurs de largeur supérieures à 500, on obtient une meilleure vision de l'effet de la variable, mais des données suspectes persistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Largeur < 40, largeur)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, si l'on se tient à des embarcations dont la largeur ne dépasse les 40 mètres, on peut voir une certaine corrélation entre la largeur et le prix de vente. Comme pour la longueur, on se doute que plus la largeur d'une embarcation est grande, plus celle-ci doit être massive et par conséquent coûteuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids = filter(row -> !ismissing(row.Poids), train)\n",
    "Gadfly.plot(poids, x=:Poids, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon son poids\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'il y a plusieurs données manquantes, nous allons utiliser une régression linéaire pour prédire ces valeurs et ainsi améliorer les variables finaux plus tard dans le rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poids = dropmissing(full_train, :Poids);\n",
    "data_poids = filter(row -> row.Longueur < 100, data_poids);\n",
    "full_train.LongueurSquare = data_poids.Longueur.^2;\n",
    "full_train.LongueurCube = data_poids.Longueur.^3;\n",
    "model_poids = lm(@formula(Poids ~ Longueur + LongueurSquare + LongueurCube), data_poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.LongueurSquare = full_train.Longueur.^2;\n",
    "full_train.LongueurCube = full_train.Longueur.^3;\n",
    "pred_poids = predict(model_poids, full_train);\n",
    "n = length(pred_poids)\n",
    "for i in 1:n\n",
    "    if (ismissing(full_train.Poids[i]))\n",
    "        full_train.Poids[i] = Int(round(pred_poids[i], digits=0))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'observer une corrélation entre le poids de l'embarcation et son prix de vente, chose qui suit notre hypothèse que plus une embarcation est grande et massive, plus elle risque de se vendre cher, dû à ses dimensions. Certaines valeurs, sont tout de même suspectes, on voit notamment une valeur de poids énorme et très éloignée des autres (plus de 400 000 lbs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, il existe malheureusement beacoup de valeurs manquantes pour le poids. Il serait donc difficile de tirer profit de cette variable sans avoir une façon d'estimer les poids manquants de nombreuses embarcations. Au moins, il semble exister une certaine relation entre la longueur d'un bateau et son poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids_train = dropmissing(train, :Longueur)\n",
    "dropmissing!(poids_train, :Poids)\n",
    "\n",
    "poids_valid = dropmissing(valid, :Longueur)\n",
    "dropmissing!(poids_valid, :Poids)\n",
    "\n",
    "Gadfly.plot(poids_train, x=:Longueur, y=:Poids, Guide.title(\"Poids d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, comme on peut le voir, le poids selon la longueur semble suivre une relation très claire et définie d'ordre 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function construct_structure(x::Vector{<:Real}, order::Int)\n",
    "    \n",
    "    X = Array{Float64}(undef, length(x), order+1)\n",
    "    \n",
    "    for p in 0:order\n",
    "       X[:,p+1] = x.^p \n",
    "    end\n",
    "    \n",
    "    return X\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = construct_structure(poids_train.Longueur, 3)\n",
    "\n",
    "β̂ = X \\ poids_train.Poids\n",
    "\n",
    "xx = collect(range(0, stop=100, length=20))\n",
    "XX = construct_structure(xx, 3)\n",
    "\n",
    "yy = XX*β̂\n",
    "\n",
    "# Affichage de la droite de régression\n",
    "model = layer(x = xx, y = yy, Geom.line, Theme(default_color=colorant\"red\"))\n",
    "points = layer(poids_train, x=:Longueur, y=:Poids, Geom.point)\n",
    "\n",
    "set_default_plot_size(15cm, 10cm)\n",
    "Gadfly.plot(points, model, Guide.yticks(), Guide.title(\"Poids d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec ce graphique on peut confirmer que le poids peut être estimé relativement bien avec la longueur selon une relation de troisième ordre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matériaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materiau = filter(row -> !ismissing(row.Materiau), train)\n",
    "Gadfly.plot(materiau, x=:Materiau, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son matériau\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir en représentant le prix des embarcations selon leur matériau, cette variable peut avoir un certain effet sur l'estimation du prix de vente. Notamment, on remarque qu'il semble que les bateaux dont le matériau est l'acier se vendent plus cher en général et ceux utilisant le pvc ont un prix moyen considérablement plus bas que ceux utilisant d'autres matériaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(materiau, :Materiau), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on regroupe les données selon le matériau de l'embarcation et que l'on évalue le nombre de bateaux classifiés comme étant composés de ce matériau et leur prix moyen, on peut encore mieux voir qu'il semble en général que les embarcations utilisant le pvc sont considérablement moins coûteuses, puis que celles utilisant de l'acier sont en moyenne vendues plus chères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(materiau, [:Type, :Materiau]), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on regroupe les données par le matériau de l'embarcation et le type, on remarque qu'il y a peu de corrélation ou lien entre eux. On peut noter que les bateaux motorisés semblent avoirune plus grande variété de matériaux et qu'ils sont les seuls à utiliser l'acier, mais peu de liens pertinent entre ces deux variables sautent aux yeux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annee_materiau = combine(groupby(materiau, [:Année, :Materiau]), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))\n",
    "Gadfly.plot(annee_materiau, x=:Année, y=:Prix_Moyen, Geom.point, color=:Materiau, Guide.title(\"Prix moyen de vente d'une embarcation selon l'année du modèle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regroupant les données par le matériau et l'année du modèle, on a encore peu de liens évidents qui sautent aux yeux. On voit que le bois comme matériau est plus commun pour des plus vieux modèles mais pour ce qui est des plus récentes décénies, il semble y avoir une variété assez claire et peu significative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables explicatives reliées aux moteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme démontré dans la matrice de corrélation des variables explicatives, les variabless en lien avec le moteur et la performance du bateau semblent avoir un effet sur le prix. Cependant, 2 des 3 variables ont des valeurs manquantes. Type_Moteur est une variables catégorielle et Puissance_Moteur est une variable quantitative. Nous allons donc devoir les traiter différemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing_Puissance_Moteur = count(ismissing, full_train[!, :Puissance_Moteur])\n",
    "num_missing_Nombre_Moteurs = count(ismissing, full_train[!, :Nombre_Moteurs])\n",
    "num_missing_Type_Moteur = count(ismissing, full_train[!, :Type_Moteur])\n",
    "\n",
    "print(\"Nombre de valeurs manquantes pour Puissance_Moteur: $num_missing_Puissance_Moteur\\n\")\n",
    "print(\"Nombre de valeurs manquantes pour Nombre_Moteurs: $num_missing_Nombre_Moteurs\\n\")\n",
    "print(\"Nombre de valeurs manquantes pour Type_Moteur: $num_missing_Type_Moteur\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgré les valeurs manquantes, nous allons tout de même analyser si ces variables ont un impact sur le prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropmissing(full_train, :Puissance_Moteur)\n",
    "Gadfly.plot(df, Scale.y_log10, Scale.x_log10, x=:Puissance_Moteur, y=:Prix, color=:Type, Geom.point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropmissing(full_train, [:Type_Moteur, :Puissance_Moteur])\n",
    "Gadfly.plot(df, Scale.y_log10, Scale.x_log10, x=:Puissance_Moteur, y=:Prix, color=:Type_Moteur, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'il est possible de remarquer que les variables Puissance_Moteur ainsi que Type_moteur peuvent avoir un pouvoir explicatif sur la variable d'intérêt, alors la prochaine étape devient de trouver une façon de gérer les données manquantes de ces colonnes. Nous avons décider d'utiliser une approche de remplacement au lieu de simplement laisser tomber les rangées contenant des valeurs manquantes puisque dans le cas contraire, l'ensemble d'entrainement serait réduit considérablement. De 12 000 données à 4144 pour être plus précis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(data_carburant, x=:Carburant, y=:Prix, Geom.boxplot)\n",
    "\n",
    "function encode_type_moteur(df::DataFrame, col_name::Symbol)\n",
    "    replace_value = \"autre_type_moteur\"\n",
    "    data[!, :Type_Moteur] = coalesce.(data[!, :Type_Moteur], replace_value);\n",
    "\n",
    "    df[!, :isOther] = zeros(Int, nrow(df))\n",
    "    df[!, :isAutre] = zeros(Int, nrow(df))\n",
    "    df[!, :isInboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard2s] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard4s] = zeros(Int, nrow(df))\n",
    "    df[!, :isVDrive] = zeros(Int, nrow(df))\n",
    "    df[!, :isInboardOutboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isMultiple] = zeros(Int, nrow(df))\n",
    "    df[!, :isElectric] = zeros(Int, nrow(df))\n",
    "\n",
    "    for i in 1:nrow(df)\n",
    "        type_moteur = df[i, col_name]\n",
    "        if type_moteur == \"other\"\n",
    "            df[i, :isOther] = 1\n",
    "        elseif type_moteur == \"autre_type_moteur\"\n",
    "            df[i, :isAutre] = 1\n",
    "        elseif type_moteur == \"inboard\"\n",
    "            df[i, :isInboard] = 1\n",
    "        elseif type_moteur == \"outboard\"\n",
    "            df[i, :isOutboard] = 1\n",
    "        elseif type_moteur == \"outboard-2s\"\n",
    "            df[i, :isOutboard2s] = 1\n",
    "        elseif type_moteur == \"outboard-4s\"\n",
    "            df[i, :isOutboard4s] = 1\n",
    "        elseif type_moteur == \"v-drive\"\n",
    "            df[i, :isVDrive] = 1\n",
    "        elseif type_moteur == \"inboard-outboard\"\n",
    "            df[i, :isInboardOutboard] = 1\n",
    "        elseif type_moteur == \"multiple\"\n",
    "            df[i, :isMultiple] = 1\n",
    "        elseif type_moteur == \"electric\"\n",
    "            df[i, :isElectric] = 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "encode_type_moteur(data, :Type_Moteur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carburant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carburant = filter(row -> !ismissing(row.Carburant), train)\n",
    "Gadfly.plot(carburant, x=:Carburant, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son carburant utilisé\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le carburant utilisé par l'embarcation a quand même une certaine importance dans le prix de vente, sachant que les embarcations utilisant le diesel se vendent en moyenne considérablement plus cher. Cependant, pour les autres types de carburant, les prix de vente semblent être relativement similaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de moteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_moteurs = filter(row -> !ismissing(row.Nombre_Moteurs), train)\n",
    "Gadfly.plot(nombre_moteurs, x=:Nombre_Moteurs, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son nombre de moteurs\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_moteurs = dropmissing(train, :Nombre_Moteurs)\n",
    "Gadfly.plot(nombre_moteurs, x=:Nombre_Moteurs, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon son nombre de moteurs\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une certaine corrélation entre le nombre de moteurs d'une embarcation et son prix de vente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puissance des moteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_moteur = dropmissing(train, :Puissance_Moteur)\n",
    "Gadfly.plot(puissance_moteur, x=:Puissance_Moteur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon la puissance du moteur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'il y a plusieurs données manquantes, nous allons utiliser une régression linéaire pour prédire ces valeurs et ainsi améliorer les variables finaux plus tard dans le rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.Puissance_Moteur = ifelse.(full_train.Type .== \"unpowered\", 1, full_train.Puissance_Moteur);\n",
    "data_puissance = dropmissing(full_train, :Puissance_Moteur);\n",
    "data_puissance = filter(row -> row.Longueur > 10, full_train);\n",
    "model_puissance = lm(@formula(Puissance_Moteur ~ Longueur + Type), data_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_puissance = predict(model_puissance, full_train);\n",
    "n = length(pred_puissance)\n",
    "for i in 1:n\n",
    "    if (ismissing(full_train.Puissance_Moteur[i]))\n",
    "        full_train.Puissance_Moteur[i] = Int(round(pred_puissance[i], digits=0))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une certaine corrélation entre la puissance du moteur d'une embarcation et son prix de vente. Selon la matrice de corrélation, la puissance des moteurs aurait un excellent pouvoir prédict, donc c'est pour cette raison que nous avons décider de faire un modèle de prédiction pour les données manquantes afin de pouvoir les utiliser dans nos prochains modèles de régression linéaires avec le Prix comme varaible d'intérêt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type de moteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Présentations des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter(row -> row.Prix < 100000, full_train);\n",
    "df_high = filter(row -> row.Prix > 100000, full_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter(row -> row.Longueur > 10, filtered_df);\n",
    "filtered_df = filter(row -> row.Longueur < 100, filtered_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "valid_high_id = sample(1:nrow(df_high), round(Int, .2nrow(df_high)), ordered=true, replace=false)\n",
    "valid_high = filtered_df[valid_high_id,:];\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];\n",
    "valid = vcat(valid, valid_high);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(full_train.Prix, bins=300, xlabel=\"Price\", ylabel=\"Frequency\", title=\"Histogram of Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé d'entraîner nos modèles de régression linéaire sur un ensemble restreint suivant une logique simple. En effet, nous avons choisi de ne pas inclure les bateaux ayant un prix supérieur à 100 000$. Cette décision est motivée par le besoin de respecter la logique implémentée par notre fonction de perte, le RMSLE. Comme mentionné précédemment, ce calcul d'erreur pénalise plus fortement les prédictions qui sont supérieures aux valeurs réelles. Donc, en enlevant toutes les données démontrant a priori l'existence de bateaux ayant des prix plus élevés, nous réduisons notre probabilité de faire des prédictions au-dessus de la valeur réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100000  \n",
    "replaced_value = size(train)[1] - sum(train.Prix .< threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(filtered_df.Prix, bins=75, xlabel=\"Price\", ylabel=\"Frequency\", title=\"Histogram of Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outre le prix, nous avons aussi remarqué que les mêmes manipulations pouvaient être appliquées à quelques variables explicatives. En effet, en enlevant environ 10% (dépendant de l'étude exploratoire) des valeurs les plus élevées de l'ensemble d'entraînement, notre modèle devenait beaucoup plus conservatif dans ses prédictions, ce qui nous permettait de réduire notre RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceValue = \"Autre\"\n",
    "train[!, :Modèle] = coalesce.(train[!, :Modèle], replaceValue);\n",
    "valid[!, :Modèle] = coalesce.(valid[!, :Modèle], replaceValue);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Modèle), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle, Category = map(assign_category, merged_df.Mean_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_category_Model!(train, model_mapping, :Modèle)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables explicatives utilisées dans ce modèle ont été choisies selon la puissance de leur relation avec le prix (démontrée par la matrice de corrélation au début de l'étude exploratoire), en combinaison avec une division catégorielle des prix puisque celle-ci nous permettait une meilleure interprétabilité des coefficients. De plus, cette catégorisation a permis au modèle de réduire la variabilité puisque chaque groupe détient des caractéristiques plus distinctes pour chaque tranche de prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(Prix ~ ((isUnder5k + is5kto10k + is10kto15k + is15kto20k + \n",
    "        is20kto25k + is25kto30k + is30kto35k + \n",
    "        is35kto40k + is40kto45k + is45kto50k + is50kto55k + \n",
    "        is55kto60k + is60kto65k + is65kto70k + is70kto75k +\n",
    "        is75kto80k + is80kto85k + is85kto90k + is90kto95k)*(Puissance_Moteur + Longueur))\n",
    "        ), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = predict(model, valid)\n",
    "# Trouver la moyenne de prediction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "# Transformer les predictions en valeur entiere\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "# Calculer le RMSLE\n",
    "v = ifelse.(v.< 0, 0, v)\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression bayesienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "data = CSV.read(\"data/train.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des données qui sont missing\n",
    "Pour la régression bayésienne avec rigde, nous avons seulement traité la longueur, la largeur, le poids, l'age, la puissance et le carburant.\n",
    "Lorsque la variable est quantitative (Longueur, poids, ...) nous avons remplacé les missing par la valeur moyenne de cette variable.\n",
    "Lorsque la variable est qualitative (carburant) nous avons remplacé les missing par le mode de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Année), nrow => :count)\n",
    "mode_Annee = counts[argmax(counts.count), :Année]\n",
    "data.Annee = coalesce.(data.Année, mode_Annee);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_longueur = mean(skipmissing(data.Longueur))\n",
    "data.Longueur = coalesce.(data.Longueur, mean_longueur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_largeur = mean(skipmissing(data.Largeur))\n",
    "data.Largeur = coalesce.(data.Largeur, mean_largeur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_poids = mean(skipmissing(data.Poids))\n",
    "mean_poids = Int(round(mean_poids, digits=0))\n",
    "data.Poids = coalesce.(data.Poids, mean_poids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Carburant), nrow => :count)\n",
    "mode_Carburant = counts[argmax(counts.count), :Carburant]\n",
    "data.Carburant = coalesce.(data.Carburant, mode_Carburant);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Nombre_Moteurs), nrow => :count)\n",
    "mode_Nombre_Moteurs = counts[argmax(counts.count), :Nombre_Moteurs]\n",
    "data.Nombre_Moteurs = coalesce.(data.Nombre_Moteurs, mode_Nombre_Moteurs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_puissance = mean(skipmissing(data.Puissance_Moteur))\n",
    "mean_puissance = Int(round(mean_puissance, digits=0))\n",
    "data.Puissance_Moteur = coalesce.(data.Puissance_Moteur, mean_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Année_Vente), nrow => :count)\n",
    "mode_Annee_Vente = counts[argmax(counts.count), :Année_Vente]\n",
    "data.Année_Vente = coalesce.(data.Année_Vente, mode_Annee_Vente);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la variable de l'age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Age = data.Année_Vente .- data.Année\n",
    "data.Age = ifelse.(data.Age .< 0, 0, data.Age);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data, x=:Age, y=:Prix, Geom.point, Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous croyons qu'il existe une corrélation entre l'age d'un bateau et son prix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la variable de la puissance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Puissance = data.Puissance_Moteur .* data.Nombre_Moteurs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data, x=:Puissance, y=:Prix, Geom.point, Scale.y_log10, Scale.x_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une corrélation entre la puissance et le prix des embarcations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation entre un ensemble d'entrainement et un ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "\n",
    "ntrain = round(Int, .8*nrow(data))\n",
    "\n",
    "train_id = sample(1:nrow(data), ntrain, replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id, :]\n",
    "valid = data[valid_id, :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df::DataFrame, column_name::Symbol)\n",
    "    unique_values = unique(df[!, column_name])\n",
    "    for value in unique_values\n",
    "        df[!, Symbol(value)] = ifelse.(df[!, column_name] .== value, 1, 0)\n",
    "    end\n",
    "    select!(df, Not(column_name))  # Supprimer la colonne d'origine\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = select(train, Not([:Prix, :ID]))\n",
    "X = select(X, [:Longueur, :Largeur, :Poids, :Age, :Puissance, :Carburant])\n",
    "X = one_hot_encode(X, :Carburant)\n",
    "Y = select(train, :Prix)\n",
    "\n",
    "# Standardisation des variables\n",
    "dt = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(X), dims=1)\n",
    "X_std = StatsBase.transform(dt, Matrix{Float64}(X))\n",
    "\n",
    "dt = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(Y), dims=1)\n",
    "Y_std = StatsBase.transform(dt, Matrix{Float64}(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation de λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = select(valid, Not([:Prix, :ID]))\n",
    "X_valid = select(X_valid, [:Longueur, :Largeur, :Poids, :Age, :Puissance, :Carburant])\n",
    "X_valid = one_hot_encode(X_valid, :Carburant)\n",
    "Y_valid = select(valid, :Prix)\n",
    "\n",
    "# Standardisation des variables\n",
    "dtx = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(X_valid), dims=1)\n",
    "X_std_valid = StatsBase.transform(dtx, Matrix{Float64}(X_valid))\n",
    "\n",
    "dty = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(Y_valid), dims=1)\n",
    "Y_std_valid = StatsBase.transform(dty, Matrix{Float64}(Y_valid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(λ = Float64[], Rmsle = Float64[])\n",
    "y_validation = StatsBase.reconstruct(dty, Y_std_valid)\n",
    "y_validation = round.(Int, y_validation)\n",
    "\n",
    "for λ = 3700:0.001:3710\n",
    "    β̂ = (X_std'X_std + λ*I)\\X_std'Y_std  # on fait la régression pour trouver les coefs.\n",
    "    \n",
    "    ŷ = X_std_valid*β̂  # on fait une prédiction (comme avant) avec les données de test\n",
    "    y_pred = StatsBase.reconstruct(dty, ŷ)\n",
    "    y_pred = round.(Int, y_pred)\n",
    "    y_pred = abs.(y_pred)\n",
    "   \n",
    "    \n",
    "    Rmsle = rmsle(y_pred[:, 1], y_validation[:, 1])  # on calcul le rmse (avec StatsBase...)\n",
    "    \n",
    "    push!(df, [λ, Rmsle])  # maintenant, il faut stocker ces résultats dans notre dataframe :\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ̂ = df.λ[argmin(df.Rmsle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(df, x=:λ, y=:Rmsle, Geom.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β̂ = (X_std'X_std + λ̂ *I)\\X_std'Y_std\n",
    "\n",
    "ŷ = X_std_valid*β̂ \n",
    "y_pred = StatsBase.reconstruct(dty, ŷ)\n",
    "y_pred = round.(Int, y_pred)\n",
    "y_pred = abs.(y_pred)\n",
    "y_validation = StatsBase.reconstruct(dty, Y_std_valid)\n",
    "y_validation = round.(Int, y_validation)\n",
    "score = rmsle(y_pred[:, 1], y_validation[:, 1])\n",
    "println(\"Le rmsle obtenu est de: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la régression de ridge, nous avons obtenu un rmsle de 0.8536. Lorsque nous avons mis notre prédiction sur kaggle, nous pensions que nous allions un score un peu meilleur que 0.8536 puisque le modèle que nous avons fait allait avoir toutes les données d'entrainement. Surprenament, nous avons obtenu un score de 2.63777. Nous croyons que cette différence est dûe à la restandardisation de la prédiction de nos prix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche de Régression linéaire par traitement de language naturel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle qui fonctionne exceptionnellement bien est venu en réponse à un problème précis. En effet, avec la régression linéaire initiale, nous avions des problèmes avec la combinaison des variable explicative. C'est à dire que celle-ci prédisaient généralement bien le prix, mais lorsque jumelés ensemble, le score calculé par rmsle ne baissait pas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour répondre à ce problème, nous avons testé ce modèle avec une seule variable explicative : Un String contenant nos variables les plus significative pour prédire le prix (Fabricant-Modèle-Longueur-Poid-Puissance-Carburant). Ainsi, avec une librairie évaluant la différence entre les strings de 0 à 1, nous utilisons simplement le modèle le plus similaire afin de déterminer son prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction permet d'enlver les espace et les chiffres pour simplifier le traitement des modèles et des fabricants\n",
    "regex_pattern = r\"\\D+\"\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "\n",
    "train[!, :Simplified_Modèle] = coalesce.(extract_model_name.(train[!, :Modèle]), \"o\")\n",
    "valid[!, :Simplified_Modèle] = coalesce.(extract_model_name.(valid[!, :Modèle]), \"o\");\n",
    "\n",
    "train[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(train[!, :Fabricant]), \"a\")\n",
    "valid[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(valid[!, :Fabricant]), \"a\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[!, :Fab_Model_Longueur] = train[!, :Simplified_Fabricant] .* \"_\" .* train[!, :Simplified_Modèle] .* \"_\" .*  train[!, :Condition] .* \"_\" .* string.(train[!, :Longueur]) .* \"_\" .* string.(train[!, :Poids]) .* \"_\" .*  string.(train[!, :Année]) .* \"_\" .* string.(train[!, :Puissance_Moteur]) .* \"_\" .* string.(train[!, :Type])\n",
    "valid[!, :Fab_Model_Longueur] = valid[!, :Simplified_Fabricant] .* \"_\" .* valid[!, :Simplified_Modèle] .* \"_\" .*  valid[!, :Condition] .* \"_\" .* string.(valid[!, :Longueur]) .* \"_\" .* string.(valid[!, :Poids]) .* \"_\" .*  string.(valid[!, :Année]) .* \"_\" .* string.(valid[!, :Puissance_Moteur]) .* \"_\" .* string.(valid[!, :Type]);\n",
    "unique_data_modèles = unique(train[!, :Fab_Model_Longueur])\n",
    "unique_valid_modèles = unique(valid[!, :Fab_Model_Longueur]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StringDistances\n",
    "# Cette fonction permet de vérifier s'il y a des modèles avec des noms similiaires, pour les regroupers par la suite\n",
    "threshold = 0.2\n",
    "mapping = Dict{String, String}()\n",
    "\n",
    "for modèle_valid in unique_valid_modèles\n",
    "    best_match = \"\"\n",
    "    best_similarity = 0.0\n",
    "    \n",
    "    for modèle_train in unique_data_modèles\n",
    "        similarity = compare(modèle_valid, modèle_train, StringDistances.Levenshtein())\n",
    "        \n",
    "        if similarity > threshold && similarity > best_similarity\n",
    "            best_match = modèle_train\n",
    "            best_similarity = similarity\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if best_match != \"\"\n",
    "        mapping[modèle_valid] = best_match\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_mapping(value) = get(mapping, value, value)\n",
    "valid[!, :Fab_Model_Longueur] .= replace_with_mapping.(valid[!, :Fab_Model_Longueur]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(Prix ~ ((Fab_Model_Longueur))), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "v = ifelse.(v.< 0, 0, v)\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse par composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chargement des données\n",
    "data = CSV.read(\"data/train.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des données qui sont missing\n",
    "Pour l'analyse en composantes principales, nous avons seulement traité le nombre de moteurs, le poids, la puissance des moteurs, la longueur et la largeur.\n",
    "Lorsque la variable est quantitative (Longueur, poids, ...) nous avons remplacé les missing par la valeur moyenne de cette variable.\n",
    "Lorsque la variable est quanlitative (nombre de moteur) nous avons remplacé les missing par le mode de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = sort(combine(groupby(dropmissing(data, :Nombre_Moteurs), :Nombre_Moteurs), nrow => :Occurence), :Occurence, rev=true).Nombre_Moteurs[1]\n",
    "data.Nombre_Moteurs = coalesce.(data.Nombre_Moteurs, mode);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_poids = mean(skipmissing(data.Poids))\n",
    "data.Poids = coalesce.(data.Poids, mean_poids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_puissance = mean(skipmissing(data.Puissance_Moteur))\n",
    "data.Puissance_Moteur = coalesce.(data.Puissance_Moteur, mean_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_longueur = mean(skipmissing(data.Longueur))\n",
    "data.Longueur = coalesce.(data.Longueur, mean_longueur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_largeur = mean(skipmissing(data.Largeur))\n",
    "data.Largeur = coalesce.(data.Largeur, mean_largeur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le traitement des variables qualitatives, nous avons fait un one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df::DataFrame, categories::Vector{T}, nom_col::Symbol) where T\n",
    "    one_hot_matrix = zeros(Int, size(df, 1), length(categories))\n",
    "    for (i, cat) in enumerate(categories)\n",
    "        one_hot_matrix[:, i] .= ifelse.(df[!, nom_col] .== cat, 1, 0)\n",
    "    end\n",
    "    return DataFrame(one_hot_matrix, Symbol.(\"one_hot_\", categories, \"_\", nom_col))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variable d'intérêt\n",
    "select!(data, [:Prix, :Longueur, :Largeur, :Nombre_Moteurs, :Poids, :Puissance_Moteur]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_Classe = unique(data.Nombre_Moteurs)\n",
    "temp = one_hot_encode(data, categories_Classe, :Nombre_Moteurs)\n",
    "data = hcat(data, temp)\n",
    "select!(data, Not(:Nombre_Moteurs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en un ensemble d'entrainement et un ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(data), round(Int, .8*nrow(data)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id, :]\n",
    "valid = data[valid_id,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle par l'analyse en composante principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "y = train[:, :Prix];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables explicatives\n",
    "select!(train, Not(:Prix));\n",
    "X = Matrix{Float64}(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'ACP pour réduire la dimensionnalité\n",
    "pca_model = fit(PCA, X, maxoutdim=8)\n",
    "\n",
    "Yte = predict(pca_model, X)\n",
    "Xr = reconstruct(pca_model, Yte)\n",
    "\n",
    "# Construire un modèle de prédiction (par exemple, régression linéaire)\n",
    "model = lm(Xr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix = valid.Prix\n",
    "select!(valid, Not(:Prix));\n",
    "X_valid = Matrix{Float64}(valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = predict(model, X_valid)\n",
    "\n",
    "# Transformer les predictions en valeur entiere\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "\n",
    "for i in 1:length(v)\n",
    "    if v[i] < 0\n",
    "        v[i] = 0\n",
    "    end\n",
    "end\n",
    "\n",
    "# Calculer le RMSLE\n",
    "score = rmsle(v, prix)\n",
    "println(\"Le rmsle obtenu est de: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait de nombreux essais avec l'analyse en composante principale, mais nous n'avons jamais réussi à avoir un meilleur rmsle de 0.96. Ainsi, nous avons fini par abandonner ce modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation des méthodes d'entrainement et validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée par k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modèle final pour la sousmission Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après tous nos tests de modèles différents, nous avons déterminé que le meilleur modèle est le ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons beaucoup appris durant ce concours. Au début, nous croyons que le modèle en analyse en composante principale ou le modèle en utilisant ridge allait être les meilleurs puisqu'il permettait d'enlever la multicolinéarité. Nous pensions aussi que nous pouvions simplement utiliser les données sans les modifier pour avoir un bon modèle. Finalement, nous avons appris que pour améliorer notre modèle, nous n'avions pas le choix de traiter les variables explicatives que nous avions pour essayer d'en trouver des nouvelles. C'est ces nouvelles variables qui nous permettaient d'améliorer nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
