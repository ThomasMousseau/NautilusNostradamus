{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Distributions, Dates, Gadfly, GLM, Statistics, Random, Plots, MultivariateStats, StatsBase, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation des fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"Data/train.csv\", DataFrame)\n",
    "test = CSV.read(\"Data/test.csv\", DataFrame)\n",
    "\n",
    "\n",
    "Random.seed!(3302)\n",
    "\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Compréhension de la métrique RMSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperçu de RMSLE\n",
    "\n",
    "La racine carrée de l'erreur quadratique moyenne logarithmique (RMSLE) est une mesure de la précision des valeurs prédites. Cependant, elle se distingue de la somme des erreurs au carré (SSE) par le fait qu'elle pénalise davantage les erreurs de prédiction des valeurs élevées par rapport aux valeurs faibles. Par conséquent, dans le cas où notre modèle serait confronté à des valeurs supérieures à celles de son ensemble d'entraînement, nous tenterons de faire en sorte que nos prédictions soient inférieures, et non supérieures, à la valeur réelle afin de minimiser la pénalité.\n",
    "\n",
    "Cette approche diffère de celle utilisée habituellement dans la régression linéaire et bayésienne, où nous souhaitons que le modèle pénalise de manière équitable les valeurs supérieures et inférieures aux valeurs prédites.\n",
    "\n",
    "C'est donc pour cette raison que vous nous verrez régulièrement exclure de notre ensemble d'entraînement des valeurs réelles qui semblent majoritairement supérieures à la moyenne observée. De cette manière, nous minimisons les probabilités que notre modèle de prédiction estime des valeurs supérieures à la réalité, sachant qu'il n'a jamais été exposé à de telles valeurs lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rmsle(predictions::Vector{Int64}, actual::Vector{Int64})\n",
    "    if length(predictions) != length(actual)\n",
    "        throw(ArgumentError(\"Les vecteurs de prédictions et de valeurs réelles doivent avoir la même longueur\"))\n",
    "    end\n",
    "    \n",
    "    n = length(predictions)\n",
    "    sum_squared_log_errors = 0\n",
    "    \n",
    "    for i in 1:n\n",
    "        sum_squared_log_errors += (log(predictions[i] + 1) - log(actual[i] + 1))^2\n",
    "    end\n",
    "    \n",
    "    rmsle_score = sqrt(sum_squared_log_errors / n)\n",
    "    return rmsle_score\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Exploration des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Matrice de correlation entre les variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé de réaliser une matrice de corrélation entre toutes les variables de l'ensemble de données afin d'avoir une idée générale de la puissance prédictive individuelle de chaque variable explicative. Cependant, il est important de noter que cette matrice ne définit que les relations entre le Prix et une variable explicative à la fois. Par conséquent, des analyses plus poussées seront nécessaires pour comprendre les liens entre plusieurs variables combinées.\n",
    "\n",
    "Toutefois, il est possible de remarquer que les variables les plus corrélées avec la variable cible sont : la Longueur, le Poids et la Puissance_Moteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(full_train)\n",
    "data = dropmissing(data)\n",
    "\n",
    "\n",
    "cols = [:Année, :Largeur, :Longueur, :Poids, :Nombre_Moteurs, :Puissance_Moteur, :Mois_Vente, :Année_Vente, :Prix]  # define subset\n",
    "M = cor(Matrix(data[!,cols]))       # correlation matrix\n",
    "\n",
    "# PLOT\n",
    "(n,m) = size(M)\n",
    "heatmap(M, fc=cgrad([:white,:dodgerblue4]), xticks=(1:m,cols), xrot=90, yticks=(1:m,cols), yflip=true)\n",
    "annotate!([(j, i, text(round(M[i,j],digits=3), 8,\"Computer Modern\",:black)) for i in 1:n for j in 1:m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Présentation des données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est à noter que les colonnes Largeur, Poids, Carburant, Puissance_moteur, ainsi que Type_Moteur présentent des données manquantes. Nous devrons donc les traiter si nous souhaitons les utiliser pour l'entraînement de notre modèle ainsi que pour valider nos modèles.\n",
    "\n",
    "Tout au long du rapport, vous verrez plusieurs façons de gérer les données manquantes, en fonction de la situation.\n",
    "\n",
    "Suppression des lignes manquantes : Cette approche était généralement utilisée pour tester rapidement une hypothèse avec une variable explicative qui, à première vue, ne possédait pas une forte puissance explicative.\n",
    "\n",
    "Remplacement par la moyenne (pour les données quantitatives) ou par \"Autre\" (pour les données qualitatives) : Cette méthode était généralement utilisée lorsqu'il y avait trop de données manquantes pour justifier le rejet de toutes les lignes contenant des données manquantes.\n",
    "\n",
    "Remplacement par un modèle de prédiction : Cette approche était généralement utilisée lorsque nous savions qu'une quantité considérable de données manquait et que nous estimions que cette variable explicative aurait un impact significatif sur la qualité de nos prédictions (par exemple, Puissance_Moteur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = mapcols(x -> count(ismissing, x), full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(12cm, 10cm)\n",
    "Gadfly.plot(train, x=:Type, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon le type d'embarcation\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les bateaux alimentés peuvent atteindre des prix très élevés, et que les bateux à voile peuvent aussi parfois être vendus très chers (plus de 1M de dollars) tandis que les bateux non alimentés n'atteignent jamais des prix exorbitants. Cela est sensé si l'on se dit que les bateux non alimentés s'agissent probablement de plus petites petites embarcations comme des kayaks, entre autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations motorisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(30cm, 10cm)\n",
    "emb_motorises = filter(row -> row.Type == \"power\", train)\n",
    "Gadfly.plot(emb_motorises, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation motorisée\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir il existe beaucoup de différentes classes pour chaque type d'embarcation. Pour plusieurs d'entre-elles, les prix semblent rester dans des ordres similaires. Cependant, comme on peut le voir par le précédent graphique, certaines classes peuvent atteindre des prix plus élevés et certaines semblent même en moyenne se vendre considérablement plus cher que d'autres, notamment les classe \"power-mega\" et \"power-passenger\". D'autres ont des prix plus bas en moyenne comme \"power-util\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_motorises, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations à voile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 10cm)\n",
    "emb_voile = filter(row -> row.Type == \"sail\", train)\n",
    "Gadfly.plot(emb_voile, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation à voile\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est des bateaux à voile, les embarcations de la classe \"sail-catamaran\" se démarquent selon leur prix de vente qui semble être considérablement plus élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_voile, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prix de vente en fonction de la classe pour les embarcations non motorisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 10cm)\n",
    "emb_non_motorises = filter(row -> row.Type == \"unpowered\", train)\n",
    "Gadfly.plot(emb_non_motorises, x=:Classe, y=:Prix, Geom.boxplot, Guide.title(\"Prix selon la classe d'embarcation non-motorisée\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, il semble que les embarcations \"unpowered-tender\" semblent être celles qui se vendent plus cher parmi les bateaux non motorisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(emb_non_motorises, :Classe), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bref la classe d'une embarcation peut certainement donner de la bonne information pour estimer son prix. Cependant, certaines classes sont plus communes dans les données que d'autres et offrent donc de meilleures estimations, tandis que d'autres sont plus rares et risquent d'être moins pertinents. De plus, il est très possible que de nouvelles données ajoutent de nouvelles classes non présentes dans celles d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fabricant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants = combine(groupby(train, :Fabricant), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))\n",
    "dropmissing!(fabricants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regroupant les données selon le fabricant, on remarque qu'il y a plus de 600 de ces derniers. Pour mieux se donner une idée de l'impact que le fabricant a sur le prix de vente final on peut donc décider de jeter un coup d'oeil aux fabricants dont le prix de vente est en moyenne le plus élevé et ceux dont le prix de vente est en moyenne le plus bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants[partialsortperm(fabricants.Prix_Moyen, 1:10, rev=true), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricants[partialsortperm(fabricants.Prix_Moyen, 1:10), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, pour certains fabricants, le prix de vente moyen de leur embarcations est très bas (entre 500 et 2000 dollars) tandis que pour d'autres, le prix est assez exorbitant (entre 1 et 2.75M de dollars). Le fabricant d'une embarcation peut donc être une information très utile pour déterminer son prix. Cependant, il y a énormément de divers fabricants et il n'y a aucune assurance que de nouvelles données n'introduisent pas de nouveux fabricants dont la moyenne de prix de vente est inconnue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_modèle_train = unique(train[:, :Modèle]); \n",
    "println(\"Number of unique categories: \", length(unique_modèle_train))\n",
    "unique_modèle_valid = unique(valid[:, :Modèle]);\n",
    "missing_modèles = setdiff(unique_modèle_valid, unique_modèle_train);\n",
    "println(\"Initially missing \" * string(length(missing_modèles)) * \" modèles in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe énormément de modèles de bateau différents (5668) et ceux-ci se répètent très peu, nous avons ainsi des doutes sur la pertinence de cette colonne de données. De plus, cette colonne est présentement inutilisation dans un modèle. Il faudra encoder un algorithme one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration = dropmissing(train, :Modèle)\n",
    "unique_categories = unique(skipmissing(exploration[:, :Modèle]))\n",
    "occurences = [sum(skipmissing(exploration[:, :Modèle]) .== category) for category in unique_categories]\n",
    "occurences = DataFrame(category = unique_categories, occurences = occurences)\n",
    "occurences = occurences[occurences.occurences .> 1, :]\n",
    "\n",
    "function calculate_statistics(category)\n",
    "    subset_data = exploration[exploration[:, :Modèle] .== category, :Prix]\n",
    "    min_prix = minimum(subset_data)\n",
    "    max_prix = maximum(subset_data)\n",
    "    mean_prix = mean(skipmissing(subset_data))\n",
    "    return (min_prix = min_prix, max_prix = max_prix, mean_prix = mean_prix)\n",
    "end\n",
    "\n",
    "prix_statistics = DataFrame([calculate_statistics(category) for category in occurences[:, :category]])\n",
    "occurences = hcat(occurences, prix_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tableau nous démontre que le modèle est un excellant prédicteur de prix. Le seul désavantage à celui-ci est qu'il en existe beaucoup. De ce fait, plusieurs modèles se retrouvent dans l'ensemble de test, mais ne sont jamais vus dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacement des variables \"Missing\" par une autre catégorie \"Autre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceValue = \"Autre\"\n",
    "train[!, :Modèle] = coalesce.(train[!, :Modèle], replaceValue);\n",
    "valid[!, :Modèle] = coalesce.(valid[!, :Modèle], replaceValue);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant sert à associer à chaque modèle connu à un intervalle de prix. Pour se faire nous utilisons la moyenne qui est plus performante que la médiane en raison de la quantité imposante de modèles observés uniquement 2 fois dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_ranges = [\n",
    "    (\"Under5k\", 0, 5000),\n",
    "    (\"5kto10k\", 5001, 10000),\n",
    "    (\"10kto15k\", 10001, 15000),\n",
    "    (\"15kto20k\", 15001, 20000),\n",
    "    (\"20kto25k\", 20001, 25000),\n",
    "    (\"25kto30k\", 25001, 30000),\n",
    "    (\"30kto35k\", 30001, 35000),\n",
    "    (\"35kto40k\", 35001, 40000),\n",
    "    (\"40kto45k\", 40001, 45000),\n",
    "    (\"45kto50k\", 45001, 50000),\n",
    "    (\"50kto55k\", 50001, 55000),\n",
    "    (\"55kto60k\", 55001, 60000),\n",
    "    (\"60kto65k\", 60001, 65000),\n",
    "    (\"65kto70k\", 65001, 70000),\n",
    "    (\"70kto75k\", 70001, 75000),\n",
    "    (\"75kto80k\", 75001, 80000),\n",
    "    (\"80kto85k\", 80001, 85000),\n",
    "    (\"85kto90k\", 85001, 90000),\n",
    "    (\"90kto95k\", 90001, 95000),\n",
    "    (\"95kto100k\", 95001, 100000)\n",
    "]\n",
    "\n",
    "# Function to assign category based on price\n",
    "function assign_category(price)\n",
    "    for (category, min_price, max_price) in price_ranges\n",
    "        if price >= min_price && price <= max_price\n",
    "            return category\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivant sert à encoder selon one-hot les tranches de prix prédéfinies plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_category_Model!(df::DataFrame, category_mapping::DataFrame, model_col::Symbol)\n",
    "    categories = unique(category_mapping.Category)\n",
    "    for category in categories\n",
    "        df[!, Symbol(\"is\", category)] = zeros(Int, nrow(df))\n",
    "    end\n",
    "\n",
    "    missing_modèle_counter = 0\n",
    "    for i in 1:nrow(df)\n",
    "        model = df[i, model_col]\n",
    "        matching_rows = filter(row -> row.Model == model, category_mapping)\n",
    "        \n",
    "        if isempty(matching_rows)\n",
    "            category = \"20kto25k\" #0.6455753480203078 #maximise le score rmsle\n",
    "            missing_modèle_counter += 1\n",
    "        else\n",
    "            category = matching_rows[1, :Category]\n",
    "        end\n",
    "    \n",
    "        df[i, Symbol(\"is\", category)] = 1\n",
    "    end\n",
    "    println(\"Missing modèles count: \", missing_modèle_counter)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1 : Tester avec le modèle. Les tests suivant (1-3) avec le rmsle sont pertinant sont d'évaluer la meilleure utilisation de la variable modèle. Les vrais test pour la prédiction du prix se trouve uniquement à vers la fin du rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by boat model and calculating mean price\n",
    "merged_df = combine(groupby(train, :Modèle), :Prix => mean => :Mean_Price)\n",
    "# Apply function to assign category to each model\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle, Category = map(assign_category, merged_df.Mean_Price))\n",
    "# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Modèle)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle)\n",
    "\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'améliorer le modèle en réduisant le nombre de modèles jamais vus. Pour ce faire, tentons de trouver des noms de modèles très similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_modèles = unique(train[!, :Modèle])\n",
    "regex_pattern = r\"\\D+\"\n",
    "# Function to extract the non-numeric part of the 'Modèle' string\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "# Apply the function to create a new column 'Modèle_New' in the train DataFrame\n",
    "train[!, :Modèle_New] = coalesce.(extract_model_name.(train[!, :Modèle]), \"Other\")\n",
    "valid[!, :Modèle_New] = coalesce.(extract_model_name.(valid[!, :Modèle]), \"Other\")\n",
    "\n",
    "# Extract unique values of 'Modèle_New' from both datasets\n",
    "unique_data_modèles = unique(train[!, :Modèle_New])\n",
    "println(\"Number of unique modèle in train: \", length(unique_data_modèles))\n",
    "unique_valid_modèles = unique(valid[!, :Modèle_New])\n",
    "println(\"Number of unique modèle in valid: \", length(unique_valid_modèles))\n",
    "diff_modèles = setdiff(unique_valid_modèles, unique_data_modèles)\n",
    "println(\"Now missing \" * string(length(diff_modèles)) * \" modèles in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cette façon, c'est à dire en oubliant les majuscules et les chiffres, nous passons de 775 à 245 modèles présents dans l'ensemble de validation, mais manquants dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #2 : Testons avec le modèle modifié (suppressions caractères spéciaux et chiffres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Modèle_New), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle_New, Category = map(assign_category, merged_df.Mean_Price))# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Modèle_New)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle_New)\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #3 : Test avec la nouvelle colonne FabModele et en réduisant avec un regex les strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée suivante provient d'une remarque au niveau du déboguage, que plusieurs modèle étaient jumelé alors que ceux-ci ne possedait pas le même fabricant cause de mauvaises probabilités avec un score rmsle plus élevés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi ce test réussi, les variables fabricant et modèle, puis utilise un regex pour enlever les chiffres et les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'Fab_Model\" in the train and valid DataFrame\n",
    "train[!, :Fab_Model] = train[!, :Fabricant] .* \"_\" .* train[!, :Modèle]\n",
    "valid[!, :Fab_Model] = valid[!, :Fabricant] .* \"_\" .* valid[!, :Modèle];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_modèles = unique(train[!, :Fab_Model])\n",
    "regex_pattern = r\"\\D+\"\n",
    "# Function to extract the non-numeric part of the 'Modèle' string\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "# Apply the function to create a new column 'Modèle_New' in the train DataFrame\n",
    "train[!, :Fab_Model] = coalesce.(extract_model_name.(train[!, :Fab_Model]), \"Other\")\n",
    "valid[!, :Fab_Model] = coalesce.(extract_model_name.(valid[!, :Fab_Model]), \"Other\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Fab_Model), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Fab_Model, Category = map(assign_category, merged_df.Mean_Price))# One Hot encoding\n",
    "encode_category_Model!(train, model_mapping, :Fab_Model)\n",
    "encode_category_Model!(valid, model_mapping, :Fab_Model)\n",
    "model_Modèle = lm(@formula(Prix ~ isUnder5k + is5kto10k + is10kto15k \n",
    "                        + is15kto20k + is20kto25k + is25kto30k \n",
    "                        + is30kto35k + is35kto40k + is40kto45k\n",
    "                        + is45kto50k + is50kto55k + is55kto60k \n",
    "                        + is60kto65k + is65kto70k + is70kto75k \n",
    "                        + is75kto80k + is80kto85k + is85kto90k \n",
    "                        + is90kto95k + is95kto100k), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model_Modèle, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Année et années de vente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_age(df::DataFrame)\n",
    "    df[!, :Age] = df[!, :Année_Vente] .- df[!, :Année]\n",
    "    logAge = ifelse.(df[!, :Age] .<= 0, 1, df[!, :Age])\n",
    "    #logAge\n",
    "    df[!, :LogAge] = (log.(logAge))\n",
    "end\n",
    "\n",
    "encode_age(full_train);\n",
    "\n",
    "full_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots.plot(full_train.Age, x=:Age, y=:Prix, Geom.point)\n",
    "\n",
    "set_default_plot_size(40cm, 20cm)\n",
    "\n",
    "plot1 = Gadfly.plot(full_train, x=:Age, y=:Prix, color=:Type, Geom.point)\n",
    "plot2 = Gadfly.plot(full_train, x=:LogAge, y=:Prix, color=:Type, Geom.point)\n",
    "\n",
    "hstack(plot1, plot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = filter(row -> !ismissing(row.Condition), train)\n",
    "set_default_plot_size(15cm, 10cm)\n",
    "Gadfly.plot(condition, x=:Condition, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon sa condition\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant une échelle de log à base 10 pour l'axe du prix pour une meilleure visibilité, on peut voir que la condition semble avoir en général peu d'importance pour prédire le prix de vente d'une embarcation. Comme on peut le voir par le précédent graphique, que l'embarcation soit neuve ou usagée, les prix de vente sont relativement similaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longueur = filter(row -> !ismissing(row.Longueur), train)\n",
    "Gadfly.plot(longueur, x=:Longueur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir possiblement une certaine corrélation entre la longueur d'une embarcation et son prix, ce qui n'est pas tout à fait surprenant. En effet, on peut faire l'hypothèse qu'en général plus une embarcation est longue, plus elle est grande et donc probablement plus coûteuse. Cependant des embarcation très longues et peu larges (très fines) ne sont pas nécéssairement alors si massives et pas autant coûteuses. Ce n'est donc pas une corrélation parfaite. Tout de même, certaines valeurs semblent être assez aberrantes, notamment les embarcations notées à des longueurs de plus de 150 pieds et dont le prix est relativement bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Longueur < 150, longueur)\n",
    "Gadfly.plot(longueur, x=:Longueur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeur = filter(row -> !ismissing(row.Largeur), train)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En prenant les données brutes, on remarque qu'il semble y avoir des données aberrantes d'embarcations aux largeurs énormes s'étant vendues à un prix relativement bas. Il vaut donc la peine de retirer ces embarcations pour mieux observer l'effet de la largeur sur le prix de vente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Largeur < 500, largeur)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En excluant des valeurs de largeur supérieures à 500, on obtient une meilleure vision de l'effet de la variable, mais des données suspectes persistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter!(row -> row.Largeur < 40, largeur)\n",
    "Gadfly.plot(largeur, x=:Largeur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon sa largeur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, si l'on se tient à des embarcations dont la largeur ne dépasse les 40 mètres, on peut voir une certaine corrélation entre la largeur et le prix de vente. Comme pour la longueur, on se doute que plus la largeur d'une embarcation est grande, plus celle-ci doit être massive et par conséquent coûteuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids = filter(row -> !ismissing(row.Poids), train)\n",
    "Gadfly.plot(poids, x=:Poids, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon son poids\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'il y a plusieurs données manquantes, nous allons utiliser une régression linéaire pour prédire ces valeurs et ainsi améliorer les variables finaux plus tard dans le rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poids = dropmissing(full_train, :Poids);\n",
    "data_poids = filter(row -> row.Longueur < 100, data_poids);\n",
    "full_train.LongueurSquare = data_poids.Longueur.^2;\n",
    "full_train.LongueurCube = data_poids.Longueur.^3;\n",
    "model_poids = lm(@formula(Poids ~ Longueur + LongueurSquare + LongueurCube), data_poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.LongueurSquare = full_train.Longueur.^2;\n",
    "full_train.LongueurCube = full_train.Longueur.^3;\n",
    "pred_poids = predict(model_poids, full_train);\n",
    "n = length(pred_poids)\n",
    "for i in 1:n\n",
    "    if (ismissing(full_train.Poids[i]))\n",
    "        full_train.Poids[i] = Int(round(pred_poids[i], digits=0))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'observer une corrélation entre le poids de l'embarcation et son prix de vente, chose qui suit notre hypothèse que plus une embarcation est grande et massive, plus elle risque de se vendre cher, dû à ses dimensions. Certaines valeurs, sont tout de même suspectes, on voit notamment une valeur de poids énorme et très éloignée des autres (plus de 400 000 lbs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, il existe malheureusement beacoup de valeurs manquantes pour le poids. Il serait donc difficile de tirer profit de cette variable sans avoir une façon d'estimer les poids manquants de nombreuses embarcations. Au moins, il semble exister une certaine relation entre la longueur d'un bateau et son poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids_train = dropmissing(train, :Longueur)\n",
    "dropmissing!(poids_train, :Poids)\n",
    "\n",
    "poids_valid = dropmissing(valid, :Longueur)\n",
    "dropmissing!(poids_valid, :Poids)\n",
    "\n",
    "Gadfly.plot(poids_train, x=:Longueur, y=:Poids, Guide.title(\"Poids d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, comme on peut le voir, le poids selon la longueur semble suivre une relation très claire et définie d'ordre 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function construct_structure(x::Vector{<:Real}, order::Int)\n",
    "    \n",
    "    X = Array{Float64}(undef, length(x), order+1)\n",
    "    \n",
    "    for p in 0:order\n",
    "       X[:,p+1] = x.^p \n",
    "    end\n",
    "    \n",
    "    return X\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = construct_structure(poids_train.Longueur, 3)\n",
    "\n",
    "β̂ = X \\ poids_train.Poids\n",
    "\n",
    "xx = collect(range(0, stop=100, length=20))\n",
    "XX = construct_structure(xx, 3)\n",
    "\n",
    "yy = XX*β̂\n",
    "\n",
    "# Affichage de la droite de régression\n",
    "model = layer(x = xx, y = yy, Geom.line, Theme(default_color=colorant\"red\"))\n",
    "points = layer(poids_train, x=:Longueur, y=:Poids, Geom.point)\n",
    "\n",
    "set_default_plot_size(15cm, 10cm)\n",
    "Gadfly.plot(points, model, Guide.yticks(), Guide.title(\"Poids d'une embarcation selon sa longueur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec ce graphique on peut confirmer que le poids peut être estimé relativement bien avec la longueur selon une relation de troisième ordre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matériaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materiau = filter(row -> !ismissing(row.Materiau), train)\n",
    "Gadfly.plot(materiau, x=:Materiau, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son matériau\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir en représentant le prix des embarcations selon leur matériau, cette variable peut avoir un certain effet sur l'estimation du prix de vente. Notamment, on remarque qu'il semble que les bateaux dont le matériau est l'acier se vendent plus cher en général et ceux utilisant le pvc ont un prix moyen considérablement plus bas que ceux utilisant d'autres matériaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(materiau, :Materiau), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on regroupe les données selon le matériau de l'embarcation et que l'on évalue le nombre de bateaux classifiés comme étant composés de ce matériau et leur prix moyen, on peut encore mieux voir qu'il semble en général que les embarcations utilisant le pvc sont considérablement moins coûteuses, puis que celles utilisant de l'acier sont en moyenne vendues plus chères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(materiau, [:Type, :Materiau]), nrow => :NbOccurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on regroupe les données par le matériau de l'embarcation et le type, on remarque qu'il y a peu de corrélation ou lien entre eux. On peut noter que les bateaux motorisés semblent avoirune plus grande variété de matériaux et qu'ils sont les seuls à utiliser l'acier, mais peu de liens pertinent entre ces deux variables sautent aux yeux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annee_materiau = combine(groupby(materiau, [:Année, :Materiau]), nrow => :NbOccurrences, :Prix => mean => Symbol(\"Prix_Moyen\"))\n",
    "Gadfly.plot(annee_materiau, x=:Année, y=:Prix_Moyen, Geom.point, color=:Materiau, Guide.title(\"Prix moyen de vente d'une embarcation selon l'année du modèle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regroupant les données par le matériau et l'année du modèle, on a encore peu de liens évidents qui sautent aux yeux. On voit que le bois comme matériau est plus commun pour des plus vieux modèles mais pour ce qui est des plus récentes décénies, il semble y avoir une variété assez claire et peu significative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables explicatives reliées aux moteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme démontré dans la matrice de corrélation des variables explicatives, les variabless en lien avec le moteur et la performance du bateau semblent avoir un effet sur le prix. Cependant, 2 des 3 variables ont des valeurs manquantes. Type_Moteur est une variables catégorielle et Puissance_Moteur est une variable quantitative. Nous allons donc devoir les traiter différemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing_Puissance_Moteur = count(ismissing, full_train[!, :Puissance_Moteur])\n",
    "num_missing_Nombre_Moteurs = count(ismissing, full_train[!, :Nombre_Moteurs])\n",
    "num_missing_Type_Moteur = count(ismissing, full_train[!, :Type_Moteur])\n",
    "\n",
    "print(\"Nombre de valeurs manquantes pour Puissance_Moteur: $num_missing_Puissance_Moteur\\n\")\n",
    "print(\"Nombre de valeurs manquantes pour Nombre_Moteurs: $num_missing_Nombre_Moteurs\\n\")\n",
    "print(\"Nombre de valeurs manquantes pour Type_Moteur: $num_missing_Type_Moteur\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgré les valeurs manquantes, nous allons tout de même analyser si ces variables ont un impact sur le prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropmissing(full_train, :Puissance_Moteur)\n",
    "Gadfly.plot(df, Scale.y_log10, Scale.x_log10, x=:Puissance_Moteur, y=:Prix, color=:Type, Geom.point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropmissing(full_train, [:Type_Moteur, :Puissance_Moteur])\n",
    "Gadfly.plot(df, Scale.y_log10, Scale.x_log10, x=:Puissance_Moteur, y=:Prix, color=:Type_Moteur, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'il est possible de remarquer que les variables Puissance_Moteur ainsi que Type_moteur peuvent avoir un pouvoir explicatif sur la variable d'intérêt, alors la prochaine étape devient de trouver une façon de gérer les données manquantes de ces colonnes. Nous avons décider d'utiliser une approche de remplacement au lieu de simplement laisser tomber les rangées contenant des valeurs manquantes puisque dans le cas contraire, l'ensemble d'entrainement serait réduit considérablement. De 12 000 données à 4144 pour être plus précis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(data_carburant, x=:Carburant, y=:Prix, Geom.boxplot)\n",
    "\n",
    "function encode_type_moteur(df::DataFrame, col_name::Symbol)\n",
    "    replace_value = \"autre_type_moteur\"\n",
    "    data[!, :Type_Moteur] = coalesce.(data[!, :Type_Moteur], replace_value);\n",
    "\n",
    "    df[!, :isOther] = zeros(Int, nrow(df))\n",
    "    df[!, :isAutre] = zeros(Int, nrow(df))\n",
    "    df[!, :isInboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard2s] = zeros(Int, nrow(df))\n",
    "    df[!, :isOutboard4s] = zeros(Int, nrow(df))\n",
    "    df[!, :isVDrive] = zeros(Int, nrow(df))\n",
    "    df[!, :isInboardOutboard] = zeros(Int, nrow(df))\n",
    "    df[!, :isMultiple] = zeros(Int, nrow(df))\n",
    "    df[!, :isElectric] = zeros(Int, nrow(df))\n",
    "\n",
    "    for i in 1:nrow(df)\n",
    "        type_moteur = df[i, col_name]\n",
    "        if type_moteur == \"other\"\n",
    "            df[i, :isOther] = 1\n",
    "        elseif type_moteur == \"autre_type_moteur\"\n",
    "            df[i, :isAutre] = 1\n",
    "        elseif type_moteur == \"inboard\"\n",
    "            df[i, :isInboard] = 1\n",
    "        elseif type_moteur == \"outboard\"\n",
    "            df[i, :isOutboard] = 1\n",
    "        elseif type_moteur == \"outboard-2s\"\n",
    "            df[i, :isOutboard2s] = 1\n",
    "        elseif type_moteur == \"outboard-4s\"\n",
    "            df[i, :isOutboard4s] = 1\n",
    "        elseif type_moteur == \"v-drive\"\n",
    "            df[i, :isVDrive] = 1\n",
    "        elseif type_moteur == \"inboard-outboard\"\n",
    "            df[i, :isInboardOutboard] = 1\n",
    "        elseif type_moteur == \"multiple\"\n",
    "            df[i, :isMultiple] = 1\n",
    "        elseif type_moteur == \"electric\"\n",
    "            df[i, :isElectric] = 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "encode_type_moteur(data, :Type_Moteur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carburant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carburant = filter(row -> !ismissing(row.Carburant), train)\n",
    "Gadfly.plot(carburant, x=:Carburant, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son carburant utilisé\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le carburant utilisé par l'embarcation a quand même une certaine importance dans le prix de vente, sachant que les embarcations utilisant le diesel se vendent en moyenne considérablement plus cher. Cependant, pour les autres types de carburant, les prix de vente semblent être relativement similaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de moteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_moteurs = filter(row -> !ismissing(row.Nombre_Moteurs), train)\n",
    "Gadfly.plot(nombre_moteurs, x=:Nombre_Moteurs, y=:Prix, Geom.boxplot, Guide.title(\"Prix de vente d'une embarcation selon son nombre de moteurs\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_moteurs = dropmissing(train, :Nombre_Moteurs)\n",
    "Gadfly.plot(nombre_moteurs, x=:Nombre_Moteurs, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon son nombre de moteurs\"), Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une certaine corrélation entre le nombre de moteurs d'une embarcation et son prix de vente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puissance des moteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_moteur = dropmissing(train, :Puissance_Moteur)\n",
    "Gadfly.plot(puissance_moteur, x=:Puissance_Moteur, y=:Prix, Geom.point, Guide.title(\"Prix de vente d'une embarcation selon la puissance du moteur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'il y a plusieurs données manquantes, nous allons utiliser une régression linéaire pour prédire ces valeurs et ainsi améliorer les variables finaux plus tard dans le rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.Puissance_Moteur = ifelse.(full_train.Type .== \"unpowered\", 1, full_train.Puissance_Moteur);\n",
    "data_puissance = dropmissing(full_train, :Puissance_Moteur);\n",
    "data_puissance = filter(row -> row.Longueur > 10, full_train);\n",
    "model_puissance = lm(@formula(Puissance_Moteur ~ Longueur + Type), data_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_puissance = predict(model_puissance, full_train);\n",
    "n = length(pred_puissance)\n",
    "for i in 1:n\n",
    "    if (ismissing(full_train.Puissance_Moteur[i]))\n",
    "        full_train.Puissance_Moteur[i] = Int(round(pred_puissance[i], digits=0))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une certaine corrélation entre la puissance du moteur d'une embarcation et son prix de vente. Selon la matrice de corrélation, la puissance des moteurs aurait un excellent pouvoir prédict, donc c'est pour cette raison que nous avons décider de faire un modèle de prédiction pour les données manquantes afin de pouvoir les utiliser dans nos prochains modèles de régression linéaires avec le Prix comme varaible d'intérêt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type de moteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Présentations des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter(row -> row.Prix < 100000, full_train);\n",
    "df_high = filter(row -> row.Prix > 100000, full_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter(row -> row.Longueur > 10, filtered_df);\n",
    "filtered_df = filter(row -> row.Longueur < 100, filtered_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "valid_high_id = sample(1:nrow(df_high), round(Int, .2nrow(df_high)), ordered=true, replace=false)\n",
    "valid_high = filtered_df[valid_high_id,:];\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];\n",
    "valid = vcat(valid, valid_high);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(full_train.Prix, bins=300, xlabel=\"Price\", ylabel=\"Frequency\", title=\"Histogram of Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé d'entraîner nos modèles de régression linéaire sur un ensemble restreint suivant une logique simple. En effet, nous avons choisi de ne pas inclure les bateaux ayant un prix supérieur à 100 000$. Cette décision est motivée par le besoin de respecter la logique implémentée par notre fonction de perte, le RMSLE. Comme mentionné précédemment, ce calcul d'erreur pénalise plus fortement les prédictions qui sont supérieures aux valeurs réelles. Donc, en enlevant toutes les données démontrant a priori l'existence de bateaux ayant des prix plus élevés, nous réduisons notre probabilité de faire des prédictions au-dessus de la valeur réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100000  \n",
    "replaced_value = size(train)[1] - sum(train.Prix .< threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(filtered_df.Prix, bins=75, xlabel=\"Price\", ylabel=\"Frequency\", title=\"Histogram of Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outre le prix, nous avons aussi remarqué que les mêmes manipulations pouvaient être appliquées à quelques variables explicatives. En effet, en enlevant environ 10% (dépendant de l'étude exploratoire) des valeurs les plus élevées de l'ensemble d'entraînement, notre modèle devenait beaucoup plus conservatif dans ses prédictions, ce qui nous permettait de réduire notre RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceValue = \"Autre\"\n",
    "train[!, :Modèle] = coalesce.(train[!, :Modèle], replaceValue);\n",
    "valid[!, :Modèle] = coalesce.(valid[!, :Modèle], replaceValue);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine(groupby(train, :Modèle), :Prix => mean => :Mean_Price)\n",
    "model_mapping = DataFrame(Model = merged_df.Modèle, Category = map(assign_category, merged_df.Mean_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_category_Model!(train, model_mapping, :Modèle)\n",
    "encode_category_Model!(valid, model_mapping, :Modèle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables explicatives utilisées dans ce modèle ont été choisies selon la puissance de leur relation avec le prix (démontrée par la matrice de corrélation au début de l'étude exploratoire), en combinaison avec une division catégorielle des prix puisque celle-ci nous permettait une meilleure interprétabilité des coefficients. De plus, cette catégorisation a permis au modèle de réduire la variabilité puisque chaque groupe détient des caractéristiques plus distinctes pour chaque tranche de prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin = lm(@formula(Prix ~ ((isUnder5k + is5kto10k + is10kto15k + is15kto20k + \n",
    "        is20kto25k + is25kto30k + is30kto35k + \n",
    "        is35kto40k + is40kto45k + is45kto50k + is50kto55k + \n",
    "        is55kto60k + is60kto65k + is65kto70k + is70kto75k +\n",
    "        is75kto80k + is80kto85k + is85kto90k + is90kto95k)*(Puissance_Moteur + Longueur))\n",
    "        ), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(model_lin, valid)\n",
    "# Trouver la moyenne de prediction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "# Transformer les predictions en valeur entiere\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "# Calculer le RMSLE\n",
    "v = ifelse.(v.< 0, 0, v)\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Validation croisée par k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validation croisée par k-fold est une technique de validation de modèle utilisée en apprentissage automatique qui vise à évaluer la capacité d'un modèle à généraliser à un ensemble de données indépendant. Le processus implique de diviser l'ensemble de données en \n",
    "k sous-ensembles. Le modèle est alors entraîné sur k−1 de ces sous-ensembles, tandis que le sous-ensemble restant est utilisé comme test pour évaluer la performance du modèle. Cette opération est répétée k fois, avec chaque sous-ensemble utilisé exactement une fois comme test.\n",
    "\n",
    "Le but de cette méthode d'utiliser toutes les données pour à la fois l'entraînement et la validation, offrant ainsi une utilisation efficace des données disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.Prix\n",
    "X = select(data_k_folds, Not(:Prix))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5  \n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    test_indices = indices[(i*fold_size + 1):min((i+1)*fold_size, n)]\n",
    "    train_indices = setdiff(indices, test_indices)\n",
    "    \n",
    "    train_data = data_k_folds[train_indices, :]\n",
    "    test_data = data_k_folds[test_indices, :]\n",
    "    \n",
    "    model_lin = lm(@formula(Prix ~ ((isUnder5k + is5kto10k + is10kto15k + is15kto20k + \n",
    "    is20kto25k + is25kto30k + is30kto35k + \n",
    "    is35kto40k + is40kto45k + is45kto50k + is50kto55k + \n",
    "    is55kto60k + is60kto65k + is65kto70k + is70kto75k +\n",
    "    is75kto80k + is80kto85k + is85kto90k + is90kto95k)*(Puissance_Moteur + Longueur))\n",
    "    ), data_k_folds)\n",
    "    \n",
    "    valid_prediction = GLM.predict(model_lin, test_data)\n",
    "    \n",
    "    mean_prediction = mean(skipmissing(valid_prediction))\n",
    "    valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "    \n",
    "    if any(ismissing, valid_prediction)\n",
    "        error(\"Skip la les valeur missing\")\n",
    "    end\n",
    "    \n",
    "    v = Int.(round.(valid_prediction, digits=0))\n",
    "    v = max.(v, 0) \n",
    "    \n",
    "    score = rmsle(v, test_data.Prix)\n",
    "    push!(rms_scores, score)\n",
    "\n",
    "end\n",
    "\n",
    "moyenne_rmsle = mean(rms_scores)\n",
    "println(\"Moyenne RMSLE : $moyenne_rmsle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, les résultats de la validation croisée ne semblent pas avoir porté leurs fruits. En effet, nous obtenons une moyenne de score RMSLE bien au-delà de celle obtenue avec la validation simple. Cela suggère qu'il y a probablement eu du sur-entraînement. Ce constat renforce notre hypothèse selon laquelle, dans cet ensemble de données, l'important était la qualité des données utilisées lors de l'entraînement et non la quantité!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Régression bayesienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"data/train.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des données qui sont missing\n",
    "Pour la régression bayésienne avec rigde, nous avons seulement traité la longueur, la largeur, le poids, l'age, la puissance et le carburant.\n",
    "Lorsque la variable est quantitative (Longueur, poids, ...) nous avons remplacé les missing par la valeur moyenne de cette variable.\n",
    "Lorsque la variable est qualitative (carburant) nous avons remplacé les missing par le mode de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Année), nrow => :count)\n",
    "mode_Annee = counts[argmax(counts.count), :Année]\n",
    "data.Annee = coalesce.(data.Année, mode_Annee);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_longueur = mean(skipmissing(data.Longueur))\n",
    "data.Longueur = coalesce.(data.Longueur, mean_longueur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_largeur = mean(skipmissing(data.Largeur))\n",
    "data.Largeur = coalesce.(data.Largeur, mean_largeur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_poids = mean(skipmissing(data.Poids))\n",
    "mean_poids = Int(round(mean_poids, digits=0))\n",
    "data.Poids = coalesce.(data.Poids, mean_poids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Carburant), nrow => :count)\n",
    "mode_Carburant = counts[argmax(counts.count), :Carburant]\n",
    "data.Carburant = coalesce.(data.Carburant, mode_Carburant);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Nombre_Moteurs), nrow => :count)\n",
    "mode_Nombre_Moteurs = counts[argmax(counts.count), :Nombre_Moteurs]\n",
    "data.Nombre_Moteurs = coalesce.(data.Nombre_Moteurs, mode_Nombre_Moteurs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_puissance = mean(skipmissing(data.Puissance_Moteur))\n",
    "mean_puissance = Int(round(mean_puissance, digits=0))\n",
    "data.Puissance_Moteur = coalesce.(data.Puissance_Moteur, mean_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(dropmissing(data), :Année_Vente), nrow => :count)\n",
    "mode_Annee_Vente = counts[argmax(counts.count), :Année_Vente]\n",
    "data.Année_Vente = coalesce.(data.Année_Vente, mode_Annee_Vente);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la variable de l'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Age = data.Année_Vente .- data.Année\n",
    "data.Age = ifelse.(data.Age .< 0, 0, data.Age);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data, x=:Age, y=:Prix, Geom.point, Scale.y_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous croyons qu'il existe une corrélation entre l'âge d'un bateau et son prix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la variable de la puissance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Puissance = data.Puissance_Moteur .* data.Nombre_Moteurs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data, x=:Puissance, y=:Prix, Geom.point, Scale.y_log10, Scale.x_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir une corrélation entre la puissance et le prix des embarcations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation entre un ensemble d'entrainement et un ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "\n",
    "ntrain = round(Int, .8*nrow(data))\n",
    "\n",
    "train_id = sample(1:nrow(data), ntrain, replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id, :]\n",
    "valid = data[valid_id, :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df::DataFrame, column_name::Symbol)\n",
    "    unique_values = unique(df[!, column_name])\n",
    "    for value in unique_values\n",
    "        df[!, Symbol(value)] = ifelse.(df[!, column_name] .== value, 1, 0)\n",
    "    end\n",
    "    select!(df, Not(column_name))  # Supprimer la colonne d'origine\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = select(train, Not([:Prix, :ID]))\n",
    "X = select(X, [:Longueur, :Largeur, :Poids, :Age, :Puissance, :Carburant])\n",
    "X = one_hot_encode(X, :Carburant)\n",
    "Y = select(train, :Prix)\n",
    "\n",
    "# Standardisation des variables\n",
    "dt = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(X), dims=1)\n",
    "X_std = StatsBase.transform(dt, Matrix{Float64}(X))\n",
    "\n",
    "dt = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(Y), dims=1)\n",
    "Y_std = StatsBase.transform(dt, Matrix{Float64}(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation de λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = select(valid, Not([:Prix, :ID]))\n",
    "X_valid = select(X_valid, [:Longueur, :Largeur, :Poids, :Age, :Puissance, :Carburant])\n",
    "X_valid = one_hot_encode(X_valid, :Carburant)\n",
    "Y_valid = select(valid, :Prix)\n",
    "\n",
    "# Standardisation des variables\n",
    "dtx = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(X_valid), dims=1)\n",
    "X_std_valid = StatsBase.transform(dtx, Matrix{Float64}(X_valid))\n",
    "\n",
    "dty = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(Y_valid), dims=1)\n",
    "Y_std_valid = StatsBase.transform(dty, Matrix{Float64}(Y_valid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(λ = Float64[], Rmsle = Float64[])\n",
    "y_validation = StatsBase.reconstruct(dty, Y_std_valid)\n",
    "y_validation = round.(Int, y_validation)\n",
    "\n",
    "for λ = 3700:0.001:3710\n",
    "    β̂ = (X_std'X_std + λ*I)\\X_std'Y_std  # on fait la régression pour trouver les coefs.\n",
    "    \n",
    "    ŷ = X_std_valid*β̂  # on fait une prédiction (comme avant) avec les données de test\n",
    "    y_pred = StatsBase.reconstruct(dty, ŷ)\n",
    "    y_pred = round.(Int, y_pred)\n",
    "    y_pred = abs.(y_pred)\n",
    "   \n",
    "    \n",
    "    Rmsle = rmsle(y_pred[:, 1], y_validation[:, 1])  # on calcul le rmse (avec StatsBase...)\n",
    "    \n",
    "    push!(df, [λ, Rmsle])  # maintenant, il faut stocker ces résultats dans notre dataframe :\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ̂ = df.λ[argmin(df.Rmsle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(df, x=:λ, y=:Rmsle, Geom.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β̂ = (X_std'X_std + λ̂ *I)\\X_std'Y_std\n",
    "\n",
    "ŷ = X_std_valid*β̂ \n",
    "y_pred = StatsBase.reconstruct(dty, ŷ)\n",
    "y_pred = round.(Int, y_pred)\n",
    "y_pred = abs.(y_pred)\n",
    "y_validation = StatsBase.reconstruct(dty, Y_std_valid)\n",
    "y_validation = round.(Int, y_validation)\n",
    "score = rmsle(y_pred[:, 1], y_validation[:, 1])\n",
    "println(\"Le rmsle obtenu est de: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la régression de ridge, nous avons obtenu un rmsle de 0.8536. Lorsque nous avons mis notre prédiction sur kaggle, nous pensions que nous allions un score un peu meilleur que 0.8536 puisque le modèle que nous avons fait allait avoir toutes les données d'entrainement. Surprenament, nous avons obtenu un score de 2.63777. Nous croyons que cette différence est dûe à la restandardisation de la prédiction de nos prix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche de Régression linéaire par traitement de language naturel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle qui fonctionne exceptionnellement bien est venu en réponse à un problème précis. En effet, avec la régression linéaire initiale, nous avions des problèmes avec la combinaison des variable explicative. C'est à dire que celle-ci prédisaient généralement bien le prix, mais lorsque jumelés ensemble, le score calculé par rmsle ne baissait pas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour répondre à ce problème, nous avons testé ce modèle avec une seule variable explicative : Un String contenant nos variables les plus significative pour prédire le prix (Fabricant-Modèle-Longueur-Poid-Puissance-Carburant). Ainsi, avec une librairie évaluant la différence entre les strings de 0 à 1, nous utilisons simplement le modèle le plus similaire afin de déterminer son prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(full_train), round(Int, .8nrow(full_train)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id,:]\n",
    "valid = full_train[valid_id,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction permet d'enlver les espace et les chiffres pour simplifier le traitement des modèles et des fabricants\n",
    "regex_pattern = r\"\\D+\"\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "\n",
    "train[!, :Simplified_Modèle] = coalesce.(extract_model_name.(train[!, :Modèle]), \"\")\n",
    "valid[!, :Simplified_Modèle] = coalesce.(extract_model_name.(valid[!, :Modèle]), \"\");\n",
    "\n",
    "train[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(train[!, :Fabricant]), \"\")\n",
    "valid[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(valid[!, :Fabricant]), \"\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[!, :Category] = train[!, :Simplified_Fabricant] .* \"_\" .* train[!, :Simplified_Modèle] .* \"_\" .* train[!, :Carburant] .* \"_\" .* train[!, :Condition] .* \"_\" .* string.(train[!, :Longueur]) .* \"_\" .* string.(train[!, :Poids]) .* \"_\" .* string.(train[!, :Année]) .* \"_\" .* string.(train[!, :Puissance_Moteur]);\n",
    "valid[!, :Category] = valid[!, :Simplified_Fabricant] .* \"_\" .* valid[!, :Simplified_Modèle] .* \"_\" .* valid[!, :Carburant] .* \"_\" .* valid[!, :Condition] .* \"_\" .* string.(valid[!, :Longueur]) .* \"_\" .* string.(valid[!, :Poids]) .* \"_\" .* string.(valid[!, :Année]) .* \"_\" .* string.(valid[!, :Puissance_Moteur]);\n",
    "unique_data_category = unique(train[!, :Category])\n",
    "unique_valid_category = unique(valid[!, :Category]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StringDistances\n",
    "# Cette fonction permet de vérifier s'il y a des modèles avec des noms similiaires, pour les regroupers par la suite\n",
    "threshold = 0.2\n",
    "mapping = Dict{String, String}()\n",
    "\n",
    "for modèle_valid in unique_valid_modèles\n",
    "    best_match = \"\"\n",
    "    best_similarity = 0.0\n",
    "    \n",
    "    for modèle_train in unique_data_modèles\n",
    "        similarity = compare(modèle_valid, modèle_train, StringDistances.Levenshtein())\n",
    "        \n",
    "        if similarity > threshold && similarity > best_similarity\n",
    "            best_match = modèle_train\n",
    "            best_similarity = similarity\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if best_match != \"\"\n",
    "        mapping[modèle_valid] = best_match\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_mapping(value) = get(mapping, value, value)\n",
    "valid[!, :Category] .= replace_with_mapping.(valid[!, :Category]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(Prix ~ ((Category))), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prediction = predict(model, valid)\n",
    "mean_prediction = mean(valid_prediction)\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "v = ifelse.(v.< 0, 0, v)\n",
    "score = rmsle(v, valid.Prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous croyons qu'une des raison pourquoi ce modèle fonctionne aussi bien est que l'utilisation de la distance de Levenshtein peut permettre de capter des variations subtiles dans les configurations de données qui sont perdues dans les modèles linéaires traditionnels. Par exemple, deux configurations très proches ayant de petites différences dans leur chaîne de caractères pourraient être identifiées comme similaires plutôt que complètement différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aussi, lorsque les variables explicatives sont nombreuses et corrélées, la régression linéaire peut souffrir de multicollinéarité ou d'autres problèmes statistiques qui affaiblissent son efficacité. La méthode basée sur la distance, en comparant les configurations complètes comme des entités uniques, permet de garder l'entièreté des valeurs et des variables explicatives sans craindre que la multicolinéarité affecte la performance du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analyse par composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"data/train.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des données qui sont missing\n",
    "Pour l'analyse en composantes principales, nous avons seulement traité le nombre de moteurs, le poids, la puissance des moteurs, la longueur et la largeur.\n",
    "Lorsque la variable est quantitative (Longueur, poids, ...) nous avons remplacé les missing par la valeur moyenne de cette variable.\n",
    "Lorsque la variable est quanlitative (nombre de moteur) nous avons remplacé les missing par le mode de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = sort(combine(groupby(dropmissing(data, :Nombre_Moteurs), :Nombre_Moteurs), nrow => :Occurence), :Occurence, rev=true).Nombre_Moteurs[1]\n",
    "data.Nombre_Moteurs = coalesce.(data.Nombre_Moteurs, mode);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_poids = mean(skipmissing(data.Poids))\n",
    "data.Poids = coalesce.(data.Poids, mean_poids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_puissance = mean(skipmissing(data.Puissance_Moteur))\n",
    "data.Puissance_Moteur = coalesce.(data.Puissance_Moteur, mean_puissance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_longueur = mean(skipmissing(data.Longueur))\n",
    "data.Longueur = coalesce.(data.Longueur, mean_longueur);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_largeur = mean(skipmissing(data.Largeur))\n",
    "data.Largeur = coalesce.(data.Largeur, mean_largeur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le traitement des variables qualitatives, nous avons fait un one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df::DataFrame, categories::Vector{T}, nom_col::Symbol) where T\n",
    "    one_hot_matrix = zeros(Int, size(df, 1), length(categories))\n",
    "    for (i, cat) in enumerate(categories)\n",
    "        one_hot_matrix[:, i] .= ifelse.(df[!, nom_col] .== cat, 1, 0)\n",
    "    end\n",
    "    return DataFrame(one_hot_matrix, Symbol.(\"one_hot_\", categories, \"_\", nom_col))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variable d'intérêt\n",
    "select!(data, [:Prix, :Longueur, :Largeur, :Nombre_Moteurs, :Poids, :Puissance_Moteur]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_Classe = unique(data.Nombre_Moteurs)\n",
    "temp = one_hot_encode(data, categories_Classe, :Nombre_Moteurs)\n",
    "data = hcat(data, temp)\n",
    "select!(data, Not(:Nombre_Moteurs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en un ensemble d'entrainement et un ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(data), round(Int, .8*nrow(data)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id, :]\n",
    "valid = data[valid_id,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle par l'analyse en composante principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "y = train[:, :Prix];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables explicatives\n",
    "select!(train, Not(:Prix));\n",
    "X = Matrix{Float64}(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'ACP pour réduire la dimensionnalité\n",
    "pca_model = fit(PCA, X, maxoutdim=8)\n",
    "\n",
    "Yte = predict(pca_model, X)\n",
    "Xr = reconstruct(pca_model, Yte)\n",
    "\n",
    "# Construire un modèle de prédiction (par exemple, régression linéaire)\n",
    "model = lm(Xr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix = valid.Prix\n",
    "select!(valid, Not(:Prix));\n",
    "X_valid = Matrix{Float64}(valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = predict(model, X_valid)\n",
    "\n",
    "# Transformer les predictions en valeur entiere\n",
    "v = Int.(round.(valid_prediction, digits=0))\n",
    "\n",
    "for i in 1:length(v)\n",
    "    if v[i] < 0\n",
    "        v[i] = 0\n",
    "    end\n",
    "end\n",
    "\n",
    "# Calculer le RMSLE\n",
    "score = rmsle(v, prix)\n",
    "println(\"Le rmsle obtenu est de: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait de nombreux essais avec l'analyse en composante principale, mais nous n'avons jamais réussi à avoir un meilleur rmsle de 0.96. Ainsi, nous avons fini par abandonner ce modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modèle final pour la sousmission Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir tester tous les différents modèles, nous avons déterminé que le meilleur modèle est la régression linéaire classique utilisant la métrique de Levenshtein. En effet, ce modèle est de loin le meilleur que nous avons pu développé en termes de qualité de prédictions. Le développement de ce modèle part de l'idée que le meilleur moyen d'estimer précisément le prix d'une embarquation de plaisance est d'utiliser une estimation ponctuelle du même modèle. \n",
    "\n",
    "Cependant, en voulant intégrer le modèle de bateau comme variable explicative, nous nous sommes confrontés à un important problème. Il faut savoir qu'un grand nombre de modèles présents dans l'ensemble de tests ne sont pas présents dans l'ensemble d'entrainement. En examinant les données de plus prêt, nous avons pu découvrir que la plupart des modèles inconnus étaient en fait très similaire à des modèles de l'ensemble d'entrainements. On pouvait d'ailleurs réduire le nombre de modèles inconnues en utilisant un simple REGEX enlevant les espaces, les nombres et convertissant la chaine en minuscule.\n",
    "Ainsi, il nous fallait trouver un moyen d'associer ces modèles légèrement différents à des modèles connus afin qu'on puisse les estimer à l'aide d'une estimation ponctuelle du modèle. \n",
    "\n",
    "Après quelques recherches, la métrique de Levenshtein nous a semblé être une option intéressante. En effet, cette algorithme nous permet de comparer le degré de ressemblances entre deux chaînes de caractères. C'est grâce à cela que nous avons pu associer les modèles inconnus de l'ensemble de tests à des modèles connus de l'ensemble d'entraînement. Ainsi, nous avons pu utiliser la colonne de modèle à son plein potentiel. Le but initial de cette approche était d'intégrer le modèle de bateau comme une variable explicative catégorielle et de l'utiliser avec d'autres variables explicatives tels que la longueur, la puissance du moteur ou le poids. Cependant, contre toute attente, l'ajout de ces variables dans le modèle de prédiction semblait augmenter notre RMSE. \n",
    "\n",
    "À partir de ce moment, nous avons décidé de mettre la majorité de nos efforts dans la conception de ce modèle de régression linéaire avec catégorisation guidée par la similarité. En ajoutant graduellement les meilleurs variables explicatives que nous avions identifiés lors de la phase d'analyse exploratoire des données, nous sommes parvenus à améliorer considérablement la qualité des prédictions de notre modèle catégorielle. En effet, nous avons donc poussé le modèle catégorielle à ses limites en intégrant toutes nos variables explicatives pertinentes. \n",
    "\n",
    "En bref, ce modèle partant initalement de l'idée d'exploiter la colonne du modèle de bateau nous a permis de constituer un modèle de régression linéaire catégorielle efficace utilisant presque toutes les colonnes. Cependant, nos connaissances actuelles nous poussent à croire que ce modèle possède ses limites. En effet, il faut savoir que celu-ci n'est pas très performant lorsqu'il rencontre un modèle de bateau inconnu et de fabricant inconnu. De plus, comme il utilise uniquement une variable explicative de catégorie, notre modèle effectue des estimations ponctuelles basés sur le prix du modèle le plus similaire de l'ensemble d'entrainement. Ainsi, il manque de flexibilité le ne peut pas s'ajuster si on a un modèle connu mais que d'autres variables sont légèrement différentes. Toutefois, la performance de ce modèle est directement proportionnel au nombre de données ce qui est un grand point fort. C'est pourquoi les résultats obtenus sur l'ensemble de test sont nettement supérieur aux résultats obtenus sur l'ensemble de validation.\n",
    "\n",
    "Voici le code permettant d'effectuer les prédictions sur l'ensemble de test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction permet d'enlver les espace et les chiffres pour simplifier le traitement des modèles et des fabricants\n",
    "regex_pattern = r\"\\D+\"\n",
    "function extract_model_name(model)\n",
    "    match_result = match(regex_pattern, replace(lowercase(string(model)), r\"\\s+\" => \"\"))\n",
    "    return match_result === nothing ? \"other\" : match_result.match\n",
    "end\n",
    "\n",
    "full_train[!, :Simplified_Modèle] = coalesce.(extract_model_name.(full_train[!, :Modèle]), \"\")\n",
    "test[!, :Simplified_Modèle] = coalesce.(extract_model_name.(test[!, :Modèle]), \"\");\n",
    "\n",
    "full_train[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(full_train[!, :Fabricant]), \"\")\n",
    "test[!, :Simplified_Fabricant] = coalesce.(extract_model_name.(test[!, :Fabricant]), \"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train[!, :Category] = full_train[!, :Simplified_Fabricant] .* \"_\" .* full_train[!, :Simplified_Modèle] .* \"_\" .* full_train[!, :Carburant] .* \"_\" .* full_train[!, :Condition] .* \"_\" .* string.(full_train[!, :Longueur]) .* \"_\" .* string.(full_train[!, :Poids]) .* \"_\" .* string.(full_train[!, :Année]) .* \"_\" .* string.(full_train[!, :Puissance_Moteur]);\n",
    "test[!, :Category] = test[!, :Simplified_Fabricant] .* \"_\" .* test[!, :Simplified_Modèle] .* \"_\" .* test[!, :Carburant] .* \"_\" .* test[!, :Condition] .* \"_\" .* string.(test[!, :Longueur]) .* \"_\" .* string.(test[!, :Poids]) .* \"_\" .* string.(test[!, :Année]) .* \"_\" .* string.(test[!, :Puissance_Moteur]);\n",
    "unique_full_train_category = unique(full_train[!, :Category])\n",
    "unique_test_category = unique(test[!, :Category]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StringDistances\n",
    "# Cette fonction permet de vérifier s'il y a des modèles avec des noms similiaires, pour les regroupers par la suite\n",
    "threshold = 0.2\n",
    "mapping = Dict{String, String}()\n",
    "\n",
    "for modèle_test in unique_test_category\n",
    "    best_match = \"\"\n",
    "    best_similarity = 0.0\n",
    "    \n",
    "    for modèle_train in unique_full_train_category\n",
    "        similarity = compare(modèle_test, modèle_train, StringDistances.Levenshtein())\n",
    "        \n",
    "        if similarity > threshold && similarity > best_similarity\n",
    "            best_match = modèle_train\n",
    "            best_similarity = similarity\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if best_match != \"\"\n",
    "        mapping[modèle_test] = best_match\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_mapping(value) = get(mapping, value, value)\n",
    "test[!, :Category] .= replace_with_mapping.(test[!, :Category]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(Prix ~ ((Category))), train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prix = full_train.Prix[argmin(data.Prix)]\n",
    "\n",
    "predictions = predict(model, test)\n",
    "predictions = Int.(round.(predictions, digits=0))\n",
    "\n",
    "predictions = ifelse.(predictions .< 0, min_prix, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_predictions = DataFrame(ID = test.ID, Prix=predictions)\n",
    "first(benchmark_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"benchmark_predictions.csv\", benchmark_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons beaucoup appris durant ce concours. Initialement, nous pensions que les modèles basés sur l'analyse en composante principale ou l'analyse bayésienne avec la régression ridge seraient les plus efficaces en raison de leur capacité à enlever la multicolinéarité. Nous pensions également que l'utilisation des données brutes suffirait à construire un bon modèle. Cependant, nous avons rapidement réalisé que pour améliorer notre modèle, il était nécessaire de traiter plus en profondeur les variables explicatives afin de découvrir de nouveaux paramètres. Ce sont ces nouvelles variables qui ont permis d'améliorer nos modèles de manière significative. Finalement, c'est le modèle avec une régression classique qui a donné les meilleurs résultats.\n",
    "\n",
    "Nous avons également été confrontés à des difficultés liées à la compréhension et à l'interprétabilité des modèles plus complexes. Cette complexité nous a parfois empêchés de saisir pleinement le fonctionnement interne de ces modèles, ce qui limitait notre capacité à les utiliser de manière efficace. C'est précisément pour cette raison que nous avons principalement investi notre temps dans la régression linéaire. Cette approche plus simple nous a permis d'avoir une meilleure compréhension du lien entre les variables et les résultats du modèle, ce qui a facilité notre processus de prise de décision.\n",
    "\n",
    "En conclusion, notre modèle pourrait être amélioré en trouvant des meilleurs modèles pour estimer le poids et la puissance des moteurs. Nous avons utilisé des modèles très simples pour ces variables, mais une meilleure approximation de ces dernières pourrait sûrement améliorer notre modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
